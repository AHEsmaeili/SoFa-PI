{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import errno\n",
    "import time\n",
    "import timeit\n",
    "import pickle\n",
    "import gc\n",
    "import re\n",
    "import glob\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union, cast\n",
    "\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "from scipy import interpolate\n",
    "from scipy import signal\n",
    "from scipy.stats.mstats import mquantiles\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.io import loadmat\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import mode\n",
    "from scipy.signal import argrelextrema, argrelmax, argrelmin\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.signal import find_peaks, peak_widths, savgol_filter\n",
    "from scipy import stats as spstats\n",
    "from scipy.stats import kurtosis, skew, mode, moment\n",
    "from scipy.signal import hilbert\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "np.seterr(all = 'ignore')\n",
    "\n",
    "from matplotlib import colors, cm\n",
    "import matplotlib.colors as mcolors\n",
    "from IPython.display import HTML, display, clear_output\n",
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "import numba\n",
    "from numba import jit\n",
    "import multiprocessing as mp\n",
    "\n",
    "import torch\n",
    "import sbi \n",
    "import sbi.inference\n",
    "from sbi.inference.base import infer\n",
    "from sbi.inference import SNPE, SNLE, SNRE, prepare_for_sbi ,simulate_for_sbi\n",
    "from sbi.inference import likelihood_estimator_based_potential, DirectPosterior, MCMCPosterior, VIPosterior\n",
    "from sbi.analysis import ActiveSubspace, pairplot\n",
    "import sbi.utils as utils\n",
    "\n",
    "import nest \n",
    "import nest.raster_plot\n",
    "nest.set_verbosity(100)\n",
    "import pylab as pl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "def LSE(x1, x2):\n",
    "    return np.sum((x1 - x2)**2)\n",
    "#####################################################\n",
    "def Err(x1, x2):\n",
    "    return np.sum(np.abs(x1 - x2))\n",
    "#####################################################    \n",
    "def RMSE(x1, x2):\n",
    "    return np.sqrt(((x1 - x2) ** 2).mean()) \n",
    "#####################################################\n",
    "def LSE_obs(Obs, Obs_lo, Obs_hi):\n",
    "    return np.average([LSE(Obs, Obs_lo), LSE(Obs, Obs_hi)])\n",
    "#####################################################\n",
    "def z_score(true_mean, post_mean, post_std):\n",
    "    return np.abs((post_mean - true_mean) / post_std)\n",
    "#####################################################\n",
    "def shrinkage(prior_std, post_std):\n",
    "    return 1 - (post_std / prior_std)**2\n",
    "#####################################################\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "from sbi.analysis.plot import _get_default_opts, _update, ensure_numpy\n",
    "\n",
    "def _get_limits(samples, limits=None):\n",
    "\n",
    "    if type(samples) != list:\n",
    "        samples = ensure_numpy(samples)\n",
    "        samples = [samples]\n",
    "    else:\n",
    "        for i, sample_pack in enumerate(samples):\n",
    "            samples[i] = ensure_numpy(samples[i])\n",
    "\n",
    "    # Dimensionality of the problem.\n",
    "    dim = samples[0].shape[1]\n",
    "\n",
    "    if limits == [] or limits is None:\n",
    "        limits = []\n",
    "        for d in range(dim):\n",
    "            min = +np.inf\n",
    "            max = -np.inf\n",
    "            for sample in samples:\n",
    "                min_ = sample[:, d].min()\n",
    "                min = min_ if min_ < min else min\n",
    "                max_ = sample[:, d].max()\n",
    "                max = max_ if max_ > max else max\n",
    "            limits.append([min, max])\n",
    "    else:\n",
    "        if len(limits) == 1:\n",
    "            limits = [limits[0] for _ in range(dim)]\n",
    "        else:\n",
    "            limits = limits\n",
    "    limits = torch.as_tensor(limits)\n",
    "\n",
    "    return limits\n",
    "\n",
    "def posterior_peaks(samples, return_dict=False, **kwargs):\n",
    "    '''\n",
    "    Finds the peaks of the posterior distribution.\n",
    "\n",
    "    Args:\n",
    "        samples: torch.tensor, samples from posterior\n",
    "    Returns: torch.tensor, peaks of the posterior distribution\n",
    "            if labels provided as a list of strings, and return_dict is True\n",
    "            returns a dictionary of peaks\n",
    "\n",
    "    '''\n",
    "\n",
    "    opts = _get_default_opts()\n",
    "    opts = _update(opts, kwargs)\n",
    "\n",
    "    limits = _get_limits(samples)\n",
    "    samples = samples.numpy()\n",
    "    n, dim = samples.shape\n",
    "\n",
    "    try:\n",
    "        labels = opts['labels']\n",
    "    except:\n",
    "        labels = range(dim)\n",
    "\n",
    "    peaks = {}\n",
    "    if labels is None:\n",
    "        labels = range(dim)\n",
    "    for i in range(dim):\n",
    "        peaks[labels[i]] = 0\n",
    "\n",
    "    for row in range(dim):\n",
    "        density = gaussian_kde(\n",
    "            samples[:, row],\n",
    "            bw_method=opts[\"kde_diag\"][\"bw_method\"])\n",
    "        xs = np.linspace(\n",
    "            limits[row, 0], limits[row, 1],\n",
    "            opts[\"kde_diag\"][\"bins\"])\n",
    "        ys = density(xs)\n",
    "\n",
    "        # y, x = np.histogram(samples[:, row], bins=bins)\n",
    "        peaks[labels[row]] = xs[ys.argmax()]\n",
    "\n",
    "    if return_dict:\n",
    "        return peaks\n",
    "    else:\n",
    "        return list(peaks.values())\n",
    "    \n",
    "def plot_posterior(samples,\n",
    "                   ax,\n",
    "                   prob=[0.025, 0.975],\n",
    "                   labels=None,\n",
    "                   xlim=None,\n",
    "                   ylim=None,\n",
    "                   xticks=None,\n",
    "                   yticks=None,\n",
    "                   xlabel=None,\n",
    "                   ylabel=None):\n",
    "\n",
    "    if ax is None:\n",
    "        print('pass axis!')\n",
    "        exit(0)\n",
    "\n",
    "    samples = samples.numpy()\n",
    "    # print(type(samples))\n",
    "    # print(samples.shape)\n",
    "    dim = samples.shape[1]\n",
    "    # assert (len(ax) == dim)\n",
    "    if labels is not None:\n",
    "        assert (len(labels) == dim)\n",
    "\n",
    "    hist_diag = {\"alpha\": 1.0, \"bins\": 50, \"density\": True, \"histtype\": \"step\"}\n",
    "\n",
    "    max_values = np.zeros(dim)\n",
    "\n",
    "    for i in range(dim):\n",
    "        ax0 = ax if (dim == 1) else ax[i]\n",
    "        n, bins, _ = ax0.hist(samples[:, i], **hist_diag)\n",
    "\n",
    "        if labels is not None:\n",
    "            ax0.set_xlabel(labels[i], fontsize=13)\n",
    "        ax0.tick_params(labelsize=12)\n",
    "\n",
    "        xs = mquantiles(samples[:, i], prob)\n",
    "\n",
    "        max_value = bins[np.argmax(n)]\n",
    "        max_values[i] = max_value\n",
    "        ax0.axvline(x=max_value, ls='--', color='gray', lw=2)\n",
    "        # for j in range(2):\n",
    "        #     ax0.axvline(x=xs[j], ls='--', color=\"royalblue\", lw=2)\n",
    "        y = n[np.where((bins > xs[0]) & (bins < xs[1]))]\n",
    "\n",
    "        ax0.fill_between(np.linspace(xs[0], xs[1], len(y)), y,\n",
    "                         color=\"gray\",\n",
    "                         alpha=0.2)\n",
    "\n",
    "        ax0.set_title(\"{:g}\".format(max_value))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return list(max_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Definition of functions used in this example. First, define the `Lambert W`\n",
    "# function implemented in SLI. The second function computes the maximum of\n",
    "# the postsynaptic potential for a synaptic input current of unit amplitude\n",
    "# (1 pA) using the `Lambert W` function. Thus function will later be used to\n",
    "# calibrate the synaptic weights.\n",
    "\n",
    "def LambertWm1(x):\n",
    "    # Using scipy to mimic the gsl_sf_lambert_Wm1 function.\n",
    "    return scp.special.lambertw(x, k=-1 if x < 0 else 0).real\n",
    "\n",
    "\n",
    "def ComputePSPnorm(tauMem, CMem, tauSyn):\n",
    "    a = (tauMem / tauSyn)\n",
    "    b = (1.0 / tauSyn - 1.0 / tauMem)\n",
    "\n",
    "    # time of maximum\n",
    "    t_max = 1.0 / b * (-LambertWm1(-np.exp(-1.0 / a) / a) - 1.0 / a)\n",
    "\n",
    "    # maximum of PSP for current of unit amplitude\n",
    "    return (np.exp(1.0) / (tauSyn * CMem * b) *\n",
    "            ((np.exp(-t_max / tauMem) - np.exp(-t_max / tauSyn)) / b -\n",
    "             t_max * np.exp(-t_max / tauSyn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to trial-separate neural timestamps\n",
    "def formatData_Spike(data, time, timeLocks, binSize, maxLead, maxLag, method):\n",
    "    \n",
    "    if len(data) != len(time):\n",
    "        raise Exception('Data and time must have equal length')\n",
    "\n",
    "    binBounds = np.linspace(-np.round(maxLead/binSize, 1),np.round(maxLag/binSize, 1), int((maxLead+maxLag)/binSize)+1)*binSize\n",
    "\n",
    "    timeBounds = np.array(list(zip(binBounds[0:-1],binBounds[1:])))\n",
    "\n",
    "    nTrials = len(timeLocks)\n",
    "    nBins = len(timeBounds)\n",
    "\n",
    "    fData = np.zeros((nBins, nTrials))\n",
    "\n",
    "    for iTrial in range(nTrials):\n",
    "\n",
    "        for iBin in range(nBins):\n",
    "            if method == 'count':\n",
    "                fData[iBin, iTrial] = np.sum(data[(time >= (timeLocks[iTrial] + timeBounds[iBin][0])) & (time < (timeLocks[iTrial] + timeBounds[iBin][1]))])\n",
    "            elif method == 'rate':\n",
    "                spkCount = np.sum(data[(time >= (timeLocks[iTrial] + timeBounds[iBin][0])) & (time < (timeLocks[iTrial] + timeBounds[iBin][1]))])     \n",
    "                fData[iBin, iTrial] = spkCount/np.diff(timeBounds[iBin,:])\n",
    "                \n",
    "    return fData, timeBounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spike_to_rate(spiketimes, nbins = 100, remove_tails = False):\n",
    "\n",
    "    spiketimes = spiketimes[np.array(spiketimes)!=None]\n",
    "\n",
    "    binned_spikes, _ = np.histogram(spiketimes, bins = nbins, range = (0,1000))\n",
    "\n",
    "    binned_fr = smooth_rates(binned_spikes, nbins = nbins, remove_tails = remove_tails)\n",
    "    \n",
    "    return binned_fr\n",
    "\n",
    "spike_to_rate = jit(spike_to_rate)\n",
    "\n",
    "def smooth_rates(firing_rate, nbins = 100, remove_tails = False, lp_filtfilt=3, lp_savgol=2, nneigh=70, savgol_order=5):\n",
    "        \n",
    "    if remove_tails:\n",
    "        lowpass = signal.butter(5, 3, 'lp', fs=nbins, output='sos')\n",
    "        firing_rate = savgol_filter(firing_rate, nneigh, savgol_order, mode = 'mirror')\n",
    "    else:\n",
    "        lowpass = signal.butter(5, 2, 'lp', fs=nbins, output='sos')\n",
    "\n",
    "    firing_rate = signal.sosfiltfilt(lowpass, firing_rate, axis = 0)\n",
    "    \n",
    "    return firing_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_axis_spines(ax, which=None, base=1.0, xticks=[], yticks=[], yaxis_left=True, xaxis_bot=True):\n",
    "\n",
    "    tick_locator = plticker.MultipleLocator(base=base)\n",
    "\n",
    "    if yaxis_left: \n",
    "        ax.spines.right.set(visible=False)\n",
    "        yspine = ax.spines.left\n",
    "    else:\n",
    "        ax.spines.left.set(visible=False)\n",
    "        yspine = ax.spines.right\n",
    "        \n",
    "    if xaxis_bot:\n",
    "        ax.spines.top.set(visible=False)\n",
    "        xspine = ax.spines.bottom\n",
    "    else:\n",
    "        ax.spines.bottom.set(visible=False)\n",
    "        xspine = ax.spines.top\n",
    "                           \n",
    "    if 'x' in which:\n",
    "        if len(xticks) == 0:\n",
    "            xticks = ax.get_xticks() \n",
    "            ax.xaxis.set_major_locator(tick_locator)\n",
    "        ax.set_xticks(xticks)\n",
    "        xspine.set_bounds(ax.get_xticks()[0], ax.get_xticks()[-1])\n",
    "        \n",
    "    else:\n",
    "        ax.spines.bottom.set(visible=False)\n",
    "    \n",
    "    if 'y' in which:\n",
    "        if len(yticks) == 0:\n",
    "            yticks = ax.get_yticks()\n",
    "        ax.set_yticks(yticks)\n",
    "        yspine.set_bounds(ax.get_yticks()[0], ax.get_yticks()[-1])\n",
    "        if len(yticks) == 0:\n",
    "            ax.yaxis.set_major_locator(tick_locator)\n",
    "    else:\n",
    "        ax.spines.left.set(visible=False)\n",
    "\n",
    "def fmt_plot_text(text):\n",
    "    return f'{text:.2f}'\n",
    "\n",
    "def get_source_time_label(time_value):\n",
    "    return 'Time from ball movement: {} ms'.format(np.round(time_value*1000))\n",
    "\n",
    "def plot_spk_avg_rates(fig, ax, firing_rates_emp, shade_colors=['cornflowerblue', 'lightcoral'], alpha=0.5, baseline=False):\n",
    "\n",
    "    p_rates = firing_rates_emp.sel(condition='Presence').copy()\n",
    "    a_rates = firing_rates_emp.sel(condition='Absence').copy()\n",
    "    \n",
    "    p_rate_avg =  p_rates.mean('neuron')\n",
    "    a_rate_avg =  a_rates.mean('neuron')\n",
    "    \n",
    "    p_rate_err = stats.sem(p_rates.to_numpy().T)\n",
    "    a_rate_err = stats.sem(a_rates.to_numpy().T)\n",
    "    \n",
    "    ax.plot(p_rates.mean('neuron'), label='Presence', c='dodgerblue');\n",
    "    ax.plot(a_rates.mean('neuron'), label='Absence', c='crimson')\n",
    "    \n",
    "    ax.fill_between(time_vec, p_rate_avg - p_rate_err, p_rate_avg + p_rate_err, color='cornflowerblue', alpha=0.5, linewidth=0)\n",
    "    ax.fill_between(time_vec, a_rate_avg - a_rate_err, a_rate_avg + a_rate_err, color='lightcoral', alpha=0.5, linewidth=0)\n",
    "    \n",
    "    ax.set_ylabel('Average firing rate')\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    \n",
    "    modify_axis_spines(ax, which = ['x', 'y'], xticks = np.arange(0, 101, 50), yticks = np.arange(np.min([p_rate_avg, a_rate_avg]), np.max([p_rate_avg, a_rate_avg])+0.1, 0.3)) \n",
    "    ax.set_xticklabels(['-500', 'FB', '500'])\n",
    "    \n",
    "    lgd = ax.legend(frameon=False)\n",
    "    \n",
    "fig.savefig(fig_save_loc + save_string + 'AllNeurons_averageFiringRate_STE_nFB.svg', transparent = True, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_sim_to_emp(sim_data, emp_data):\n",
    "\n",
    "    emp_range = emp_data.max() - emp_data.min()\n",
    "    sim_range = sim_data.max() - sim_data.min()\n",
    "\n",
    "    range_ratio = emp_range/sim_range\n",
    "\n",
    "    sim_data *= range_ratio\n",
    "\n",
    "    start_diff = emp_data[0] - sim_data[0]\n",
    "    sim_data += start_diff\n",
    "\n",
    "    return sim_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_save_loc = ''\n",
    "save_string = 'SPK/'\n",
    "parent_preprocess_dir = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brunel model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "nest.ResetKernel()\n",
    "n = 8  # number of threads\n",
    "\n",
    "nest.SetKernelStatus({'local_num_threads': n, 'print_time': False})\n",
    "\n",
    "startbuild = time.time()\n",
    "\n",
    "dt = 0.1    # the resolution in ms\n",
    "simtime = 1000.0  # Simulation time in ms\n",
    "delay = 1.5    # synaptic delay in ms\n",
    "\n",
    "g = 5.8  # ratio inhibitory weight/excitatory weight\n",
    "eta = 1.5  # external rate relative to threshold rate\n",
    "epsilon = 0.1  # connection probability\n",
    "\n",
    "order = 2500\n",
    "NE = 4 * order  # number of excitatory neurons\n",
    "NI = 1 * order  # number of inhibitory neurons\n",
    "N_neurons = NE + NI   # number of neurons in total\n",
    "N_rec = 100      # record from 50 neurons\n",
    "\n",
    "CE = int(epsilon * NE)  # number of excitatory synapses per neuron\n",
    "CI = int(epsilon * NI)  # number of inhibitory synapses per neuron\n",
    "C_tot = int(CI + CE)      # total number of synapses per neuron\n",
    "\n",
    "tauSyn = 0.5  # synaptic time constant in ms\n",
    "tauMem = 20.0  # time constant of membrane potential in ms\n",
    "CMem = 250.0  # capacitance of membrane in in pF\n",
    "theta = 20.0  # membrane threshold potential in mV\n",
    "\n",
    "neuron_params = {\"C_m\": CMem,\n",
    "                 \"tau_m\": tauMem,\n",
    "                 \"tau_syn_ex\": tauSyn,\n",
    "                 \"tau_syn_in\": tauSyn,\n",
    "                 \"t_ref\": 2.0,\n",
    "                 \"E_L\": 0.0,\n",
    "                 \"V_reset\": 10.0,\n",
    "                 \"V_m\": 0.0,\n",
    "                 \"V_th\": theta}\n",
    "\n",
    "J = 0.1        # postsynaptic amplitude in mV\n",
    "J_unit = ComputePSPnorm(tauMem, CMem, tauSyn)\n",
    "J_ex = J / J_unit  # amplitude of excitatory postsynaptic current\n",
    "J_in = -g * J_ex    # amplitude of inhibitory postsynaptic current\n",
    "\n",
    "nu_th = (theta * CMem) / (J_ex * CE * np.exp(1) * tauMem * tauSyn)\n",
    "nu_ex = eta * nu_th\n",
    "p_rate = 1000.0 * nu_ex * CE\n",
    "# p_rate = 9000\n",
    "\n",
    "nest.resolution = dt\n",
    "nest.print_time = True\n",
    "nest.overwrite_files = True\n",
    "\n",
    "nodes_ex = nest.Create(\"iaf_psc_alpha\", NE, params=neuron_params)\n",
    "nodes_in = nest.Create(\"iaf_psc_alpha\", NI, params=neuron_params)\n",
    "noise = nest.Create(\"poisson_generator\", params={\"rate\": p_rate})\n",
    "espikes = nest.Create(\"spike_recorder\")\n",
    "ispikes = nest.Create(\"spike_recorder\")\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Set external current\n",
    "\n",
    "pop_stepcurrent = nest.Create('noise_generator', n = 1)\n",
    "\n",
    "time_start = 350\n",
    "time_end = 900\n",
    "meanCurr = 150\n",
    "stdCurr = 1\n",
    "\n",
    "pop_stepcurrent.set(start = time_start, stop = time_end, mean = meanCurr, std = stdCurr)\n",
    "nest.Connect(pop_stepcurrent, nodes_ex, syn_spec={'weight': 1.})\n",
    "pop_stepcurrent.set(start = time_start, stop = time_end, mean = meanCurr, std = stdCurr)\n",
    "nest.Connect(pop_stepcurrent, nodes_in, syn_spec={'weight': 1.})\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "espikes.set(label=\"brunel-py|-ex\", record_to=\"memory\")\n",
    "ispikes.set(label=\"brunel-py-in\", record_to=\"memory\")\n",
    "\n",
    "nest.CopyModel(\"static_synapse\", \"excitatory\",\n",
    "               {\"weight\": J_ex, \"delay\": delay})\n",
    "nest.CopyModel(\"static_synapse\", \"inhibitory\",\n",
    "               {\"weight\": J_in, \"delay\": delay})\n",
    "\n",
    "nest.Connect(noise, nodes_ex, syn_spec=\"excitatory\")\n",
    "nest.Connect(noise, nodes_in, syn_spec=\"excitatory\")\n",
    "\n",
    "nest.Connect(nodes_ex[:N_rec], espikes, syn_spec=\"excitatory\")\n",
    "nest.Connect(nodes_in[:N_rec], ispikes, syn_spec=\"excitatory\")\n",
    "\n",
    "conn_params_ex = {'rule': 'fixed_indegree', 'indegree': CE}\n",
    "nest.Connect(nodes_ex, nodes_ex + nodes_in, conn_params_ex, \"excitatory\")\n",
    "\n",
    "conn_params_in = {'rule': 'fixed_indegree', 'indegree': CI}\n",
    "nest.Connect(nodes_in, nodes_ex + nodes_in, conn_params_in, \"inhibitory\")\n",
    "\n",
    "endbuild = time.time()\n",
    "\n",
    "nest.Simulate(simtime)\n",
    "\n",
    "endsimulate = time.time()\n",
    "\n",
    "events_ex = espikes.n_events\n",
    "events_in = ispikes.n_events\n",
    "\n",
    "rate_ex = events_ex / simtime * 1000.0 / N_rec\n",
    "rate_in = events_in / simtime * 1000.0 / N_rec\n",
    "\n",
    "num_synapses_ex = nest.GetDefaults(\"excitatory\")[\"num_connections\"]\n",
    "num_synapses_in = nest.GetDefaults(\"inhibitory\")[\"num_connections\"]\n",
    "num_synapses = num_synapses_ex + num_synapses_in\n",
    "\n",
    "ex_senders = espikes.events['senders']\n",
    "in_senders = ispikes.events['senders']\n",
    "ex_times = espikes.events['times']\n",
    "in_times = ispikes.events['times']\n",
    "\n",
    "# np.savez_compressed(file = 'tempSim.npz',g = g, ex_senders = ex_senders, in_senders = in_senders, ex_times = ex_times, in_times = in_times)\n",
    "\n",
    "nest.raster_plot.from_device(espikes, hist=True, hist_binwidth=30.0)\n",
    "# plt.savefig(fig_save_loc + 'Brunel_Nest_testsim.png', dpi = 400, transparent = True)\n",
    "plt.title('Sample brunel simulation')\n",
    "# plt.savefig(fig_save_loc + save_string + 'Brunel_Nest_testsim.png', dpi = 400, transparent = True)\n",
    "plt.show()\n",
    "print(endsimulate - endbuild)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate_brunel(g, save_name = '', save_path = '', save_results = False):\n",
    "    \n",
    "    ###############################################################################\n",
    "    # Setting up simulation parameters\n",
    "    \n",
    "    g = np.array(g).ravel()[0]\n",
    "    \n",
    "    dt = 0.1    # the resolution in ms\n",
    "    simtime = 1000.0  # Simulation time in ms    \n",
    "    num_workers = 8  # number of threads\n",
    "    \n",
    "    nest.ResetKernel()\n",
    "    nest.SetKernelStatus({'local_num_threads': num_workers, \"print_time\": False, \"overwrite_files\": True})\n",
    "    nest.resolution = dt\n",
    "\n",
    "    ###############################################################################\n",
    "    # Neural parameters\n",
    "    \n",
    "    ctime_start = 350 # start of external current\n",
    "    ctime_end = 900 # end of external current\n",
    "    meanCurr = 150\n",
    "    stdCurr = 1\n",
    "    \n",
    "    delay = 1.5    # synaptic delay in ms\n",
    "    eta = 1  # external rate relative to threshold rate\n",
    "    tauSyn = 0.5  # synaptic time constant in ms\n",
    "    tauMem = 20.0  # time constant of membrane potential in ms\n",
    "    CMem = 250.0  # capacitance of membrane in in pF\n",
    "    theta = 20.0  # membrane threshold potential in mV\n",
    "    \n",
    "    neuron_params = {\"C_m\": CMem,\n",
    "                     \"tau_m\": tauMem,\n",
    "                     \"tau_syn_ex\": tauSyn,\n",
    "                     \"tau_syn_in\": tauSyn,\n",
    "                     \"t_ref\": 2.0,\n",
    "                     \"E_L\": 0.0,\n",
    "                     \"V_reset\": 10.0,\n",
    "                     \"V_m\": 0.0,\n",
    "                     \"V_th\": theta}\n",
    "    \n",
    "    \n",
    "    J = 0.1        # postsynaptic amplitude in mV\n",
    "    J_unit = ComputePSPnorm(tauMem, CMem, tauSyn)\n",
    "    J_ex = J / J_unit  # amplitude of excitatory postsynaptic current\n",
    "    J_in = -g * J_ex    # amplitude of inhibitory postsynaptic current\n",
    "        \n",
    "    ###############################################################################\n",
    "    # Network parameters\n",
    "    \n",
    "    order = 2500\n",
    "    NE = 4 * order  # number of excitatory neurons\n",
    "    NI = 1 * order  # number of inhibitory neurons\n",
    "    N_neurons = NE + NI   # number of neurons in total\n",
    "    epsilon = 0.1  # connection probability\n",
    "    N_rec = 100      # record from N_rec neurons\n",
    "\n",
    "    CE = int(epsilon * NE)  # number of excitatory synapses per neuron\n",
    "    CI = int(epsilon * NI)  # number of inhibitory synapses per neuron\n",
    "    C_tot = int(CI + CE)      # total number of synapses per neuron\n",
    "    \n",
    "    conn_params_ex = {'rule': 'fixed_indegree', 'indegree': CE}\n",
    "    conn_params_in = {'rule': 'fixed_indegree', 'indegree': CI}\n",
    "    \n",
    "    ###############################################################################\n",
    "    # Rate of external poisson input\n",
    "    \n",
    "    nu_th = (theta * CMem) / (J_ex * CE * np.exp(1) * tauMem * tauSyn)\n",
    "    nu_ex = eta * nu_th\n",
    "    p_rate = 1000.0 * nu_ex * CE\n",
    "    \n",
    "    ###############################################################################\n",
    "    # Set recorders and stimulator\n",
    "    \n",
    "    nodes_ex = nest.Create(\"iaf_psc_alpha\", NE, params=neuron_params)\n",
    "    nodes_in = nest.Create(\"iaf_psc_alpha\", NI, params=neuron_params)\n",
    "    noise = nest.Create(\"poisson_generator\", params={\"rate\": p_rate})\n",
    "    espikes = nest.Create(\"spike_recorder\")\n",
    "    ispikes = nest.Create(\"spike_recorder\")\n",
    "    pop_stepcurrent = nest.Create('noise_generator', n = 1)\n",
    "\n",
    "    ###############################################################################\n",
    "    # Set recorders and stimulator\n",
    "    \n",
    "    pop_stepcurrent.set(start = ctime_start, stop = ctime_end, mean = meanCurr, std = stdCurr)\n",
    "    pop_stepcurrent.set(start = ctime_start, stop = ctime_end, mean = meanCurr, std = stdCurr)\n",
    "    espikes.set(label=\"brunel-ex\", record_to=\"memory\")\n",
    "    ispikes.set(label=\"brunel-in\", record_to=\"memory\")\n",
    "\n",
    "    nest.CopyModel(\"static_synapse\", \"excitatory\",\n",
    "                   {\"weight\": J_ex, \"delay\": delay})\n",
    "    nest.CopyModel(\"static_synapse\", \"inhibitory\",\n",
    "                   {\"weight\": J_in, \"delay\": delay})\n",
    "\n",
    "    ###############################################################################\n",
    "    # Connect network elements\n",
    "    \n",
    "    nest.Connect(pop_stepcurrent, nodes_ex, syn_spec={'weight': 1.})\n",
    "    nest.Connect(pop_stepcurrent, nodes_in, syn_spec={'weight': 1.})\n",
    "\n",
    "    nest.Connect(noise, nodes_ex, syn_spec=\"excitatory\")\n",
    "    nest.Connect(noise, nodes_in, syn_spec=\"excitatory\")\n",
    "\n",
    "    nest.Connect(nodes_ex[:N_rec], espikes, syn_spec=\"excitatory\")\n",
    "    nest.Connect(nodes_in[:N_rec], ispikes, syn_spec=\"excitatory\")\n",
    "    \n",
    "    nest.Connect(nodes_ex, nodes_ex + nodes_in, conn_params_ex, \"excitatory\")\n",
    "    nest.Connect(nodes_in, nodes_ex + nodes_in, conn_params_in, \"inhibitory\")\n",
    "    \n",
    "    nest.Simulate(simtime)\n",
    "\n",
    "    ###############################################################################\n",
    "    # Save spike times to disk\n",
    "    ex_senders = espikes.events['senders']\n",
    "    in_senders = ispikes.events['senders']\n",
    "    ex_times = espikes.events['times']\n",
    "    in_times = ispikes.events['times']\n",
    "\n",
    "    if not save_path.endswith('/'):\n",
    "        save_path = save_path + '/'\n",
    "    \n",
    "    if save_results:\n",
    "        np.savez_compressed(file = save_path + save_name + '.npz', g=g, ex_senders=ex_senders, in_senders=in_senders, ex_times=ex_times, in_times=in_times)\n",
    "    else:\n",
    "        return ex_senders, ex_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = 10000\n",
    "\n",
    "spk_sbi_dir ='./DCM_SPK_SBI/' \n",
    "save_name = 'brunel_delta_' + str(num_sims) + '_sims_'\n",
    "save_path =  spk_sbi_dir + 'input/' + save_name[:-1] + '/simulations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior over model parameters\n",
    "prior_min = [5.]\n",
    "prior_max = [8.]\n",
    "prior = utils.torchutils.BoxUniform(low=torch.as_tensor(prior_min),\n",
    "                                    high=torch.as_tensor(prior_max))\n",
    "\n",
    "theta = prior.sample((num_sims,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stime = time.time()\n",
    "\n",
    "for ind, sim_num in enumerate(trange(1,num_sims+1)):\n",
    "    \n",
    "    simulate_brunel(theta[ind], save_path = save_path , save_name = save_name + str(sim_num), save_results = True)\n",
    "    \n",
    "etime = time.time()\n",
    "print('Total time: {}'.format(etime - stime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = []\n",
    "\n",
    "ex_senders_agg = []\n",
    "in_senders_agg = []\n",
    "ex_times_agg = []\n",
    "in_times_agg = []\n",
    "\n",
    "for ind, sim_num in enumerate(trange(1,num_sims+1)):\n",
    "    \n",
    "    tempsim = np.load(file = save_path + save_name + str(sim_num) + '.npz')\n",
    "    theta.append(tempsim['g'])\n",
    "    ex_senders_agg.append(tempsim['ex_senders'])\n",
    "    in_senders_agg.append(tempsim['in_senders'])\n",
    "    ex_times_agg.append(tempsim['ex_times'])\n",
    "    in_times_agg.append(tempsim['in_times'])\n",
    "\n",
    "theta = np.array(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_lens = np.array([len(senders) for senders in ex_senders_agg])\n",
    "in_lens = np.array([len(senders) for senders in in_senders_agg])\n",
    "\n",
    "max_ex_len = np.max(ex_lens)\n",
    "max_in_len = np.max(in_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = ('data', 'sim', 'source')\n",
    "coords = {'source': ['neuron_ind', 'spike_time']}\n",
    "\n",
    "ex_array = np.empty((max_ex_len, num_sims, 2), dtype=object)\n",
    "in_array = np.empty((max_in_len, num_sims, 2), dtype=object)\n",
    "\n",
    "ex_array = xr.DataArray(ex_array, dims=dims, coords=coords, attrs={'Origin': 'Excitatory cells'})\n",
    "in_array = xr.DataArray(in_array, dims=dims, coords=coords, attrs={'Origin': 'Inhibitory cells'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sInd in trange(num_sims):\n",
    "    \n",
    "    ex_array[:ex_lens[sInd], sInd, 0] = ex_senders_agg[sInd]\n",
    "    ex_array[:ex_lens[sInd], sInd, 1] = ex_times_agg[sInd]\n",
    "    \n",
    "    in_array[:in_lens[sInd], sInd, 0] = in_senders_agg[sInd]\n",
    "    in_array[:in_lens[sInd], sInd, 1] = in_times_agg[sInd]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation firing rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sInd = 4316\n",
    "sample_times = ex_array[:,sInd,1]\n",
    "sample_ids = ex_array[:,sInd,0]\n",
    "\n",
    "sample_times = sample_times[np.array(sample_times)!=None]\n",
    "sample_ids = sample_ids[np.array(sample_ids)!=None]\n",
    "\n",
    "nbins = 100\n",
    "sample_fr, _ = np.histogram(sample_times, bins=nbins, range=(0,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowpass = signal.butter(5, 2, 'lp', fs=nbins, output='sos')\n",
    "\n",
    "new_fr = smooth_rates(sample_fr, remove_tails=True)\n",
    "plt.plot(sample_fr);plt.plot(new_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_rates_sim = np.zeros((sample_fr.shape[0], num_sims))\n",
    "\n",
    "for sim_num in trange(num_sims):\n",
    "    \n",
    "    spike_times = ex_array.sel(source = 'spike_time', sim = sim_num)\n",
    "    firing_rate = spike_to_rate(spike_times, remove_tails = True)\n",
    "    firing_rates_sim[:, sim_num] = firing_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_sims_path = spk_sbi_dir + 'input/' + save_name[:-1]\n",
    "\n",
    "if not os.path.isdir(spk_sims_path):\n",
    "    os.mkdir(spk_sims_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['max', 'argmax', 'mean']\n",
    "# sel_features = feature_names\n",
    "sel_features = ['max']\n",
    "\n",
    "\n",
    "firing_rates_sim_norm = firing_rates_sim.copy()\n",
    "firing_rates_sim_norm /= firing_rates_sim_norm.max()\n",
    "firing_rates_sim_norm += 1\n",
    "firing_rates_sim_norm /= 2\n",
    "\n",
    "\n",
    "fr_maxs_sim = firing_rates_sim.max(0)[...,None]\n",
    "fr_avgs_sim = firing_rates_sim.mean(0)[...,None]\n",
    "fr_argmaxs_sim = firing_rates_sim.argmax(0)[...,None]\n",
    "\n",
    "normalize=True\n",
    "if normalize:\n",
    "    fr_maxs_sim = preprocessing.MinMaxScaler().fit_transform(fr_maxs_sim.reshape(-1,1))\n",
    "    fr_avgs_sim = preprocessing.MinMaxScaler().fit_transform(fr_avgs_sim.reshape(-1,1))\n",
    "\n",
    "fr_summary_sim = np.concatenate((fr_maxs_sim, fr_argmaxs_sim, fr_avgs_sim), axis=1)\n",
    "fr_summary_sim = xr.DataArray(fr_summary_sim, dims=('sample', 'feature'), coords=dict(feature=feature_names))\n",
    "\n",
    "x_feature_array = fr_summary_sim.copy()\n",
    "x_features = fr_summary_sim.copy().sel(feature=sel_features)\n",
    "\n",
    "num_features = len(x_feature_array.feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_rates_sim_norm = firing_rates_sim.copy()\n",
    "\n",
    "fr_maxs = firing_rates_sim_norm.max(0)\n",
    "fr_maxs = preprocessing.MinMaxScaler().fit_transform(fr_maxs.reshape(-1,1))\n",
    "\n",
    "plt.scatter(theta, fr_maxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(file=spk_sims_path + '/input_data.npz', theta=theta, firing_rates=firing_rates_sim)\n",
    "x_features.to_netcdf(spk_sims_path + '/features.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = np.load(spk_sims_path + '/input_data.npz')\n",
    "theta = data_dict['theta']\n",
    "firing_rates_sim = data_dict['firing_rates']\n",
    "\n",
    "x_feature_array = xr.load_dataarray(spk_sims_path + '/features.nc')\n",
    "sel_features = ['max']\n",
    "feature_string = '-'.join(sel_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = np.array(x_feature_array.to_numpy(), dtype='float32')\n",
    "x_features = torch.as_tensor(x_features)\n",
    "\n",
    "theta = np.array(theta, dtype='float32')\n",
    "theta = theta.reshape(theta.shape[0],1)\n",
    "theta = torch.as_tensor(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'Theta shape:',theta.shape,flush=True)\n",
    "print('Feature shape:', x_features.shape,flush=True)\n",
    "print('Features: ' + feature_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(firing_rates_sim, 'k', alpha=0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(theta, x_features[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_type = 'nsf'\n",
    "\n",
    "posterior_string = save_name + feature_string + '_' + estimator_type\n",
    "print(posterior_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "inference = SNPE(prior, density_estimator=estimator_type, device='cpu')\n",
    "\n",
    "posterior_estimator = inference.append_simulations(theta, x_features).train()\n",
    "\n",
    "print (\"-\"*60)\n",
    "print(\"---training took:  %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "with open(spk_sbi_dir + 'output/estimators/'  + posterior_string + '.pkl', 'wb') as f:\n",
    "    pickle.dump(posterior_estimator,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_file = open(spk_sbi_dir + 'output/estimators/'  + posterior_string + '.pkl', \"rb\")\n",
    "posterior_estimator = pickle.load(posterior_file)\n",
    "posterior_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_rates_emp = xr.load_dataarray(parent_preprocess_dir + 'Demolliens_SPK_rates_norm.nc')\n",
    "neuron_names = firing_rates_emp.neuron.to_numpy()\n",
    "time_vec = firing_rates_emp.time.to_numpy()\n",
    "\n",
    "firing_rates_emp_stacked = firing_rates_emp.stack(condSamples=('condition', 'neuron'))\n",
    "condition_array = firing_rates_emp_stacked.condition.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_spk_avg_rates(fig, ax, firing_rates_emp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_maxs_emp = firing_rates_emp_stacked.max('time').to_numpy()[...,None]\n",
    "fr_argmaxs_emp = firing_rates_emp_stacked.argmax('time').to_numpy()[...,None]\n",
    "fr_avgs_emp = firing_rates_emp_stacked.mean('time').to_numpy()[...,None]\n",
    "\n",
    "fr_summary_emp = np.concatenate((fr_maxs_emp, fr_argmaxs_emp, fr_avgs_emp), axis=1)\n",
    "fr_summary_emp = xr.DataArray(fr_summary_emp, dims=('sample', 'feature'), coords=dict(feature=feature_names))\n",
    "\n",
    "emp_features = fr_summary_emp.copy().sel(feature=sel_features)\n",
    "num_emp_samples = firing_rates_emp_stacked.condSamples.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples=1000\n",
    "posterior = DirectPosterior(posterior_estimator, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "theta_posterior = np.zeros((num_samples, num_emp_samples))\n",
    "\n",
    "for s_ind in range(num_emp_samples):\n",
    "    display(f\"Iteration: {s_ind}\")\n",
    "    theta_posterior[:, s_ind] = posterior.sample((num_samples,), emp_features.isel(sample=s_ind).to_numpy()).numpy().squeeze()    \n",
    "    clear_output()\n",
    "\n",
    "posteriorMaxs = np.array(posterior_peaks(torch.as_tensor(theta_posterior), return_dict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_posterior_array = xr.DataArray(theta_posterior, dims=('sample', 'condition'), coords=dict(condition=condition_array))\n",
    "theta_posterior_stacked = theta_posterior_array.stack(aggSample=('sample', 'condition'))\n",
    "\n",
    "posterior_df = theta_posterior_stacked.to_pandas().reset_index().rename(columns={0: 'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'condition'\n",
    "y = 'value'\n",
    "palette = {'Presence': 'dodgerblue', 'Absence': 'crimson'}\n",
    "\n",
    "bw = 0.1\n",
    "width_viol = 0.5\n",
    "orient = 'v'\n",
    "alpha = .99\n",
    "dodge = True\n",
    "pointplot = False\n",
    "move = 0.2\n",
    "point_size = 0\n",
    "cut = 0.5\n",
    "scale = 'area'\n",
    "width_box = 0.5\n",
    "line_width = 0.1\n",
    "saturation = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [r'$g$']\n",
    "lw=1\n",
    "\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "\n",
    "violins = sns.boxplot(x=x, y=y, data=posterior_df, fliersize=0,\n",
    "               palette=palette, saturation = 0.8, dodge=True, ax=ax, linewidth = 2)\n",
    "\n",
    "annotator = Annotator(x=x, y=y, ax=ax, pairs=[('Presence','Absence')], data=posterior_df,)\n",
    "annotator.configure(test='Mann-Whitney', text_format='star', loc='outside', line_width=lw)\n",
    "annotator.apply_and_annotate()\n",
    "\n",
    "ax.tick_params(axis='both', which='major', length=0)\n",
    "ax.set_xlabel('', labelpad = 12)\n",
    "ax.set_ylabel(r'$g$', labelpad = 12)\n",
    "ax.set_ylim([5.5, 6.1])\n",
    "ax.set_frame_on(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriorMaxs = xr.DataArray(posteriorMaxs, dims=('sample_2'), coords=dict(sample_2=condition_array))\n",
    "posterior_array = xr.DataArray(posterior_df['value'].to_numpy(), dims=('sample_1'), coords=dict(sample_1=posterior_df['condition'].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_data = xr.Dataset(dict(posterior_array=posterior_array, posterior_maxs=posteriorMaxs))\n",
    "posterior_data.to_netcdf(parent_preprocess_dir + 'Demolliens_SPK_AllNeurons_Posterior.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average firing rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_mean = firing_rates_emp.sel(condition='Presence').copy().mean('neuron')\n",
    "absence_mean = firing_rates_emp.sel(condition='Absence').copy().mean('neuron')\n",
    "\n",
    "mean_rates = np.array([presence_mean, absence_mean]).T\n",
    "\n",
    "plt.plot(mean_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_avg_maxs = mean_rates.mean(0)[...,None]\n",
    "fr_avg_argmax = mean_rates.argmax(0)[...,None]\n",
    "fr_avg_means = mean_rates.mean(0)[...,None]\n",
    "\n",
    "fr_avg_summary = np.concatenate((fr_avg_maxs, fr_avg_argmax, fr_avg_means), axis=1)\n",
    "fr_avg_summary = xr.DataArray(fr_avg_summary, dims=('sample', 'feature'), coords=dict(feature=feature_names))\n",
    "\n",
    "emp_features = fr_avg_summary.copy().sel(feature=sel_features)\n",
    "num_emp_samples = emp_features.sample.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "theta_posterior_avg = np.array([posterior.sample((num_samples,), emp_features.isel(sample=s_ind).to_numpy()).numpy() for s_ind in range(num_emp_samples)]).squeeze().T\n",
    "posteriorMaxs_avg = np.array(posterior_peaks(torch.as_tensor(theta_posterior_avg), return_dict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_posterior_avg = xr.DataArray(theta_posterior_avg, dims=('sample', 'condition'), coords=dict(condition=['Presence', 'Absence']))\n",
    "theta_posterior_stacked = theta_posterior_avg.stack(aggSample=('sample', 'condition'))\n",
    "\n",
    "posterior_df_avg = theta_posterior_stacked.to_pandas().reset_index().rename(columns={0: 'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriorCheckSims = []\n",
    "\n",
    "posterior_neuron_inds = []\n",
    "posterior_spike_times = []\n",
    "spike_times_lengths = []\n",
    "\n",
    "for cInd in range(2):\n",
    "    neuron_inds, spike_times = simulate_brunel(posteriorMaxs_avg[cInd])\n",
    "    posterior_spike_times.append(spike_times)\n",
    "    posterior_neuron_inds.append(neuron_inds)\n",
    "    spike_times_lengths.append(len(spike_times))\n",
    "    \n",
    "    checkSim = spike_to_rate(spike_times, remove_tails=False)\n",
    "    posteriorCheckSims.append(checkSim)\n",
    "\n",
    "posteriorCheckSims = np.array(posteriorCheckSims).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_spike_number = max(spike_times_lengths)\n",
    "\n",
    "posterior_check_spikes = xr.DataArray(np.zeros((max_spike_number, 2, 2)), dims=('index', 'source', 'condition'),\n",
    "                                      coords=dict(source=['times', 'indices'], condition=['Presence','Absence']))\n",
    "\n",
    "for c_ind in range(2):\n",
    "    times_length = spike_times_length[c_ind]\n",
    "    \n",
    "    posterior_check_spikes[:times_length, 0, c_ind] = posterior_spike_times[c_ind]\n",
    "    posterior_check_spikes[:times_length, 1, c_ind] = posterior_neuron_inds[c_ind]\n",
    "\n",
    "    posterior_check_spikes[times_length:, :, c_ind] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCheckSims = posteriorCheckSims.copy()\n",
    "mean_rates = np.array([presence_mean, absence_mean]).T\n",
    "plotCheckSims = np.array([scale_sim_to_emp(posteriorCheckSims[:,ind].copy(), mean_rates[:,ind]) for ind in range(2)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, constrained_layout = True)\n",
    "\n",
    "alpha = 1\n",
    "\n",
    "maxLead = 0.5\n",
    "maxLag = 0.5\n",
    "timeVec = np.linspace(-maxLead*1000, maxLag*1000, mean_rates.shape[0])\n",
    "tv = np.linspace(-maxLead*1000, maxLag*1000, posteriorCheckSims.shape[0])\n",
    "\n",
    "ax.plot(timeVec, mean_rates[:,0], label = 'Emp-Pr', c = 'blue', lw =5, alpha = alpha)\n",
    "ax.plot(timeVec, mean_rates[:,1], label = 'Emp-Ab', c = 'red', lw = 5, alpha = alpha)\n",
    "\n",
    "ax.plot(tv, plotCheckSims[:,0].ravel(), label = 'SBI-Pr', lw = 6, c = 'cornflowerblue', ls = ':');\n",
    "ax.plot(tv, plotCheckSims[:,1].ravel(), label = 'SBI-Ab', lw = 6, c = 'salmon', ls = ':');\n",
    "\n",
    "ax.set_xlabel('Scaled Time', fontsize = 15, labelpad = 12)\n",
    "ax.set_ylabel('Normalized Firing Rate', fontsize = 15, labelpad = 10)\n",
    "ax.legend(fontsize = 12, frameon = False, loc = (0.2, 1.05), ncol = 2)\n",
    "ax.set_frame_on(False)\n",
    "ax.tick_params(labelsize = 12, length = 0)\n",
    "# ax.set_xlim([-500, 500])\n",
    "fig.tight_layout()\n",
    "fig.savefig(fig_save_loc + 'SBI_SPK_Timeseries_' + saveString  + '.png', transparent = True, dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rates = xr.DataArray(mean_rates, dims=('time', 'condition'), coords=dict(condition=['Presence', 'Absence']))\n",
    "plotCheckSims = xr.DataArray(plotCheckSims, dims=('time', 'condition'), coords=dict(condition=['Presence', 'Absence']))\n",
    "posterior_array = xr.DataArray(posterior_df_avg['value'].to_numpy(), dims=('sample'), coords=dict(sample=posterior_df_avg['condition'].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_data = xr.Dataset(dict(posterior_array=posterior_array, posterior_checks=plotCheckSims, posterior_check_spikes=posterior_check_spikes, emp_rates=mean_rates))\n",
    "posterior_data.to_netcdf(parent_preprocess_dir + 'Demolliens_SPK_AvgNeurons_Posterior.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "af3958ab9377742790c05849326d0b326323eecd8a6dd64f51a3be8fe30e9d4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
