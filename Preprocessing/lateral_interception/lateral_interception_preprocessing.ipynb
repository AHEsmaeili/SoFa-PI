{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c306b85f-6e41-4939-9878-ecc7dab1b52b",
   "metadata": {},
   "source": [
    "# Imports & Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756a1f96-7e30-496e-9527-063a4fa26722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os.path import join, dirname, realpath, exists\n",
    "import json\n",
    "import gc\n",
    "import glob\n",
    "import inspect\n",
    "import time\n",
    "from copy import copy, deepcopy\n",
    "from io import StringIO\n",
    "from itertools import combinations\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy import signal, stats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing, manifold\n",
    "import xarray as xr\n",
    "\n",
    "# %matplotlib qt\n",
    "import seaborn as sns\n",
    "import ptitprince as pt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib import colors, cm\n",
    "import matplotlib.colors as mcolors\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from statannotations.Annotator import Annotator\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['FreeSans']})\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "from matplotlib.font_manager import get_font_names\n",
    "from IPython.display import display, Math, Latex, HTML, clear_output\n",
    "from vtk.util import numpy_support\n",
    "\n",
    "import numba\n",
    "import numpyro as npr\n",
    "import numpyro.infer\n",
    "from numpyro import distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from scipy.integrate import solve_ivp, quad\n",
    "import arviz as az\n",
    "\n",
    "\n",
    "import mne\n",
    "from mne.preprocessing import (ICA, corrmap)\n",
    "from mne.datasets import fetch_fsaverage\n",
    "import mne_connectivity\n",
    "\n",
    "mne.utils.set_config('MNE_USE_CUDA', 'true')\n",
    "mne.set_log_level('error')  # reduce extraneous MNE output\n",
    "mne.viz.set_browser_backend('qt')\n",
    "\n",
    "# Example_dir = dirname(realpath(__file__)) # directory of this file\n",
    "modules_dir = '' # directory with all TMSI modules\n",
    "sys.path.append(modules_dir)\n",
    "\n",
    "%matplotlib qt\n",
    "# %matplotlib inline\n",
    "    \n",
    "from TMSiFileFormats.file_readers import Poly5Reader\n",
    "\n",
    "from autoreject import get_rejection_threshold\n",
    "from autoreject import Ransac  # noqa\n",
    "from autoreject.utils import interpolate_bads  # noqa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a78062-11b7-4bf3-8200-790836d5386b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load data and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea977b41-8bca-4967-b360-a16d520306cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directories\n",
    "save_string = 'EEG/'\n",
    "fig_save_loc = ''\n",
    "preprocess_dir = ''\n",
    "parent_preprocess_dir = ''\n",
    "measurements_dir = '' # directory with all measurements\n",
    "poly5_dirs = glob.glob(measurements_dir + '**/*.Poly5', recursive=True)\n",
    "\n",
    "subject_folders = glob.glob(measurements_dir + 'pongFac23*')\n",
    "subjects = np.array([subj.split('_')[-1] for subj in subject_folders])\n",
    "subject_metrics = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b78068f-cef9-449f-8b7e-22ff2c0de909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_axis_spines(ax, which=None, base=1.0, xticks=[], yticks=[], yaxis_left=True, xaxis_bot=True):\n",
    "\n",
    "    tick_locator = plticker.MultipleLocator(base=base)\n",
    "\n",
    "    if yaxis_left: \n",
    "        ax.spines.right.set(visible=False)\n",
    "        yspine = ax.spines.left\n",
    "    else:\n",
    "        ax.spines.left.set(visible=False)\n",
    "        yspine = ax.spines.right\n",
    "        \n",
    "    if xaxis_bot:\n",
    "        ax.spines.top.set(visible=False)\n",
    "        xspine = ax.spines.bottom\n",
    "    else:\n",
    "        ax.spines.bottom.set(visible=False)\n",
    "        xspine = ax.spines.top\n",
    "                           \n",
    "    if 'x' in which:\n",
    "        if len(xticks) == 0:\n",
    "            xticks = ax.get_xticks() \n",
    "            ax.xaxis.set_major_locator(tick_locator)\n",
    "        ax.set_xticks(xticks)\n",
    "        xspine.set_bounds(ax.get_xticks()[0], ax.get_xticks()[-1])\n",
    "        \n",
    "    else:\n",
    "        ax.spines.bottom.set(visible=False)\n",
    "    \n",
    "    if 'y' in which:\n",
    "        if len(yticks) == 0:\n",
    "            yticks = ax.get_yticks()\n",
    "        ax.set_yticks(yticks)\n",
    "        yspine.set_bounds(ax.get_yticks()[0], ax.get_yticks()[-1])\n",
    "        if len(yticks) == 0:\n",
    "            ax.yaxis.set_major_locator(tick_locator)\n",
    "    else:\n",
    "        ax.spines.left.set(visible=False)\n",
    "\n",
    "def fmt_plot_text(text):\n",
    "    return f'{text:.2f}'\n",
    "\n",
    "def get_source_time_label(time_value):\n",
    "    return 'Time from ball movement: {} ms'.format(np.round(time_value*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c0ef6-2f77-40ea-9bff-f7fb589150ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_function(x, a, b):\n",
    "    return (a*x + b)\n",
    "\n",
    "def nonlinear_function(x, a, b, c, d):\n",
    "    return (a + b*x + c*x**2 + d*x**3)\n",
    "\n",
    "def linreg_system(N, y, x=None):\n",
    "    a = npr.sample('a', dist.Normal(0, 10))\n",
    "    b = npr.sample('b', dist.Normal(50, 100))\n",
    "    sigma= npr.sample('sigma', dist.HalfNormal(100))\n",
    "    xdot = npr.deterministic('xdot', linear_function(x=x, a=a, b=b))\n",
    "\n",
    "    with npr.plate('N', N):\n",
    "        npr.sample('obs', dist.Normal(xdot, sigma), obs=y)\n",
    "\n",
    "def nonlinear_system(N, y, x=None):\n",
    "    a = npr.sample('a', dist.Normal(0, 10))\n",
    "    b = npr.sample('b', dist.Normal(0, 10))\n",
    "    c = npr.sample('c', dist.Normal(0, 10))\n",
    "    d = npr.sample('d', dist.Normal(0, 10))\n",
    "    sigma= npr.sample('sigma', dist.HalfNormal(10))\n",
    "    xdot = npr.deterministic('xdot', nonlinear_function(x=x, a=a, b=b, c=c, d=d))\n",
    "\n",
    "    with npr.plate('N', N):\n",
    "        npr.sample('obs', dist.Normal(xdot, sigma), obs=y)\n",
    "\n",
    "def run_mcmc_from_system(target_system, x, y, num_warmup = 1000, num_samples = 2000):\n",
    "\n",
    "    N = x.size\n",
    "\n",
    "    if type(x) == xr.core.dataarray.DataArray:\n",
    "        x = x.to_numpy()\n",
    "\n",
    "    nuts_kernel = NUTS(target_system, adapt_step_size=True)\n",
    "    mcmc = MCMC(nuts_kernel, num_chains=1, num_warmup=num_warmup, num_samples=num_samples)\n",
    "    rng_key = jax.random.PRNGKey(0)\n",
    "    mcmc.run(rng_key, N=N, y=y, x=x)\n",
    "\n",
    "    return mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465414eb-5488-4b2b-a593-9716a702f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FC(data, fc_only=True):\n",
    "    \n",
    "    fc = np.corrcoef(data)\n",
    "    cov = np.cov(data)\n",
    "\n",
    "    if fc_only:\n",
    "        return fc\n",
    "    else:\n",
    "        return fc, cov\n",
    "\n",
    "def tri_zero_mask(n_rows, n_cols, k=0, upper=True):\n",
    "\n",
    "    mask = np.ones((n_rows, n_cols))    \n",
    "    zero_mask = np.tri(n_rows, n_cols, dtype=bool, k=k)\n",
    "    mask[zero_mask] = 0\n",
    "    \n",
    "    if not upper:\n",
    "        mask = mask.T\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc3269e-095b-4527-8dc6-a2ea8fd5ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_args(func):\n",
    "    signature = inspect.signature(func)\n",
    "    return {\n",
    "        k: v.default\n",
    "        for k, v in signature.parameters.items()\n",
    "        if v.default is not inspect.Parameter.empty\n",
    "    }\n",
    "\n",
    "\n",
    "def find_nearest(array, values):\n",
    "    # make sure array is a numpy array\n",
    "    array = np.array(array)\n",
    "\n",
    "    # get insert positions\n",
    "    idxs = np.searchsorted(array, values, side=\"left\")\n",
    "    \n",
    "    # find indexes where previous index is closer\n",
    "    prev_idx_is_less = ((idxs == len(array))|(np.fabs(values - array[np.maximum(idxs-1, 0)]) < np.fabs(values - array[np.minimum(idxs, len(array)-1)])))\n",
    "    idxs[prev_idx_is_less] -= 1\n",
    "    \n",
    "    return array[idxs], idxs\n",
    "\n",
    "def formatData(data, time, timeLocks, binSize, maxLead, maxLag, sr = 120, isComplex = False):\n",
    "    \n",
    "    if len(data) != len(time):\n",
    "        raise Exception('Data and time must have equal length')\n",
    "\n",
    "    num_trials = len(timeLocks)\n",
    "    \n",
    "    rangeInds = np.round(np.array([-maxLead*sr, maxLag*sr], dtype = np.int64))\n",
    "    \n",
    "    nearestTimes, nearestInds = find_nearest(time, timeLocks)\n",
    "    beginInds = nearestInds - rangeInds[0]\n",
    "    endInds = nearestInds + rangeInds[-1]\n",
    "    \n",
    "    fData = np.zeros((np.sum(rangeInds), data.shape[1], num_trials))\n",
    "\n",
    "    if isComplex:\n",
    "        fData = fData.astype(complex)\n",
    "    \n",
    "    for trialInd in range(num_trials):\n",
    "        \n",
    "        trial_data = data[beginInds[trialInd] : endInds[trialInd],:]\n",
    "        trial_length = trial_data.shape[0]\n",
    "        \n",
    "        if trial_length >= fData.shape[0]:\n",
    "            fData[:, :, trialInd] = trial_data\n",
    "        else:\n",
    "            fData[:trial_length, :, trialInd] = trial_data\n",
    "    \n",
    "    return fData\n",
    "\n",
    "def smooth_rates(firing_rate, nbins = 100, remove_tails = False, axis = -1, order = 5, lp_savgol = 3, lp_filtfilt = 2):\n",
    "    \n",
    "    nneigh = 10\n",
    "    \n",
    "    if remove_tails:\n",
    "        lowpass = signal.butter(order, lp_savgol, 'lp', fs=nbins, output='sos')\n",
    "        firing_rate = signal.savgol_filter(firing_rate, nneigh, order, mode = 'mirror', axis = axis)\n",
    "    else:\n",
    "        lowpass = signal.butter(order, lp_filtfilt, 'lp', fs=nbins, output='sos')\n",
    "\n",
    "    firing_rate = signal.sosfiltfilt(lowpass, firing_rate, axis = axis)\n",
    "    \n",
    "    return firing_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2827a5-7134-4a30-846c-5dd5fae825b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pong_session(sub_dir, nTrials=160, event_label='startTrig0', binSize=1, maxLead=0.2, maxLag=3, frame_rate=120, output_all=True):\n",
    "    \n",
    "    behav_dir = os.path.join(sub_dir, 'Pong')\n",
    "\n",
    "    sub_trials = glob.glob(behav_dir + '/test_*kin_*.csv')\n",
    "    sub_behav = sub_trials[0].split('_kin_')[0]+'.csv'\n",
    "    sub_trials = sorted(sub_trials, key=lambda fname: int(fname.split('_kin_')[-1].split('.')[0]))\n",
    "    \n",
    "    session_data = pd.read_csv(sub_behav, nrows = nTrials)\n",
    "    time_locks = session_data[event_label]\n",
    "\n",
    "    movement_data = []\n",
    "    \n",
    "    for trial, trial_file in enumerate(sub_trials):\n",
    "        trialdf = pd.read_csv(trial_file)\n",
    "        movement_data.append(trialdf)\n",
    "        \n",
    "        if trial == 0:\n",
    "            mvm = trialdf['p1x']\n",
    "            tst = trialdf['t']\n",
    "            by = trialdf['by']\n",
    "            bx = trialdf['bx']\n",
    "        else:\n",
    "            mvm = np.concatenate((mvm, trialdf['p1x']))\n",
    "            tst = np.concatenate((tst, trialdf['t']))\n",
    "            by = np.concatenate((by, trialdf['by']))\n",
    "            bx = np.concatenate((bx, trialdf['bx']))\n",
    "\n",
    "    mvm = mvm.reshape(-1,1)\n",
    "    tst = tst.reshape(-1,1)\n",
    "    by = by.reshape(-1,1)\n",
    "    bx = bx.reshape(-1,1)\n",
    "        \n",
    "    if output_all:\n",
    "        binned_data_trials = formatData(np.concatenate((mvm, tst, by, bx), axis = 1), tst.squeeze(), time_locks, binSize, maxLead, maxLag, sr = frame_rate)\n",
    "    else:    \n",
    "        binned_data_trials = formatData(mvm, tst.squeeze(), time_locks, binSize, maxLead, maxLag, sr = frame_rate).squeeze()\n",
    "\n",
    "    return session_data, movement_data, binned_data_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5189ce-0476-4669-bebc-dd3b802fe3ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_raw_tmsi(data_path, subject_name, subject_folder, pong_results, overwrite=True, check_channel_names=False):\n",
    "\n",
    "    ch_default_names = ['Fp1', 'Fpz', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1',\n",
    "                       'FC2', 'FC6', 'M1', 'T7', 'C3', 'Cz', 'C4', 'T8', 'M2', 'CP5',\n",
    "                       'CP1', 'CP2', 'CP6', 'P7', 'P3', 'Pz', 'P4', 'P8', 'POz', 'O1',\n",
    "                       'Oz', 'O2', 'AF7', 'AF3', 'AF4', 'AF8', 'F5', 'F1', 'F2', 'F6',\n",
    "                       'FC3', 'FCz', 'FC4', 'C5', 'C1', 'C2', 'C6', 'CP3', 'CPz', 'CP4',\n",
    "                       'P5', 'P1', 'P2', 'P6', 'PO5', 'PO3', 'PO4', 'PO6', 'FT7', 'FT8',\n",
    "                       'TP7', 'TP8', 'PO7', 'PO8', 'TRIGGERS', 'STATUS',\n",
    "                       'Counter 2power24']\n",
    "    \n",
    "    data = Poly5Reader(data_path)\n",
    "    raw = data.read_data_MNE()\n",
    "\n",
    "    if check_channel_names:\n",
    "        if raw.ch_names != ch_default_names:\n",
    "            temp_ch_names = raw.info['ch_names']\n",
    "            ch_mappings = {temp_ch_names[cInd]: ch_default_names[cInd] for cInd in range(len(temp_ch_names))}\n",
    "            raw.rename_channels(ch_mappings)\n",
    "\n",
    "    raw.drop_channels(['Counter 2power24', 'TRIGGERS'])\n",
    "\n",
    "    channels = np.array(raw.ch_names)\n",
    "    eegChs = channels[:64]\n",
    "    miscChs = channels[64:]\n",
    "    chTypes = {}\n",
    "    for channel in channels:\n",
    "        if channel not in miscChs:\n",
    "            chTypes[channel] = 'eeg'\n",
    "        elif channel == 'STATUS':\n",
    "            chTypes[channel] = 'stim'\n",
    "    \n",
    "    raw.set_channel_types(chTypes)\n",
    "    raw.set_montage('standard_1005')\n",
    "    \n",
    "    # Removing & Interpolating bad channels\n",
    "    print('Removing bad channels')\n",
    "    bmEvents, fbEvents, conditions, intercepts = calculate_events(raw, pong_results, subject=subject_name, filter_events=False)\n",
    "    \n",
    "    raw.info['bads'] = []\n",
    "    epoch_events = bmEvents\n",
    "    epoch_ids = {'Interception': 1, 'Miss': -1}\n",
    "    tmin = -0.5\n",
    "    tmax = 1\n",
    "    \n",
    "    raw_epochs = mne.Epochs(raw, epoch_events, epoch_ids, tmin, tmax,\n",
    "                    baseline=(None, -0.2), reject=None,\n",
    "                    verbose=False, detrend=0, preload=True)\n",
    "    picks = mne.pick_types(raw_epochs.info, eeg=True, include=[], exclude=[])\n",
    "    ransac = Ransac(verbose=False, picks=picks, n_jobs=8)\n",
    "    raw_epochs_clean = ransac.fit_transform(raw_epochs)\n",
    "\n",
    "    raw.info['bads'] = ransac.bad_chs_\n",
    "    raw.interpolate_bads()\n",
    "    raw.set_eeg_reference(ref_channels='average')\n",
    "\n",
    "    # ICA computation\n",
    "    print('Computing ICA')\n",
    "    \n",
    "    low_cut = 1\n",
    "    high_cut = 45\n",
    "    n_jobs = 8\n",
    "    n_comp = 30\n",
    "    stop = 900\n",
    "    method = 'fir'\n",
    "    \n",
    "    raw.filter(low_cut, high_cut, n_jobs='cuda', method=method)\n",
    "\n",
    "    ica = ICA(n_components=n_comp, method='fastica', max_iter='auto', random_state=97)\n",
    "    icaEvts = mne.make_fixed_length_events(raw, start=25, stop=stop)\n",
    "    icaEpochs = mne.Epochs(raw, events=icaEvts, baseline=None)\n",
    "    reject = get_rejection_threshold(icaEpochs);\n",
    "    ica.fit(icaEpochs, reject=reject)\n",
    "    ica.save(subject_folder + '/EEG/' + subject_name + '_ica.fif', overwrite=True)\n",
    "\n",
    "\n",
    "    # Removing eye-blinks and saccades components\n",
    "    corrmap([ica], blink_template, threshold=0.9, plot=False, label='blink')\n",
    "    ica.exclude.extend(ica.labels_['blink'])\n",
    "    \n",
    "    if (subject_name == 'p17'):\n",
    "        pass\n",
    "    else:\n",
    "        corrmap([ica], saccade_template, threshold = 0.9, plot = False, label = 'saccade')\n",
    "        ica.exclude.extend(ica.labels_['saccade'])\n",
    "    \n",
    "    ica.apply(raw)\n",
    "    raw.save(subject_folder + '/EEG/' + subject_name + '_raw_clean.fif', overwrite=True)\n",
    "\n",
    "    # Source localization\n",
    "    print('Source localization')\n",
    "    raw.set_eeg_reference(projection=True)\n",
    "\n",
    "    # Download fsaverage files\n",
    "    mne_fs_dir = ''\n",
    "    fs_dir = fetch_fsaverage(verbose=True, subjects_dir=mne_fs_dir)\n",
    "        \n",
    "    # The files live in:\n",
    "    subject = \"fsaverage\"\n",
    "    trans = \"fsaverage\"  # MNE has a built-in fsaverage transformation\n",
    "    src = os.path.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "    bem = os.path.join(fs_dir, \"bem\", \"fsaverage-5120-5120-5120-bem-sol .fif\")\n",
    "    fwd = mne.make_forward_solution(raw.info, trans=trans, src=src, bem=bem, eeg=True, mindist=5.0, n_jobs=n_jobs)\n",
    "    \n",
    "    epochs = mne.Epochs(raw, bmEvents, tmin=-0.5, tmax=1.0, proj=True, picks='eeg', baseline=(None, -0.2), preload=True)    \n",
    "    cov = mne.compute_covariance(epochs, method='auto', tmax=-0.2, n_jobs=n_jobs)\n",
    "    inv = mne.minimum_norm.make_inverse_operator(raw.info, fwd, cov, loose=0.2)\n",
    "\n",
    "    mne.write_cov(fname=subject_folder + '/EEG/' + subject_name + '_cov.fif', cov=cov, overwrite=True)\n",
    "    mne.write_forward_solution(fname=subject_folder + '/EEG/' + subject_name + '_fwd.fif', fwd=fwd, overwrite=True)\n",
    "    mne.minimum_norm.write_inverse_operator(fname=subject_folder + '/EEG/' + subject_name + '_inv.fif', inv=inv, overwrite=True)\n",
    "    \n",
    "    del(data, raw, raw_epochs, raw_epochs_clean, icaEpochs, ica, epochs, cov, inv)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca072ea3-d284-4995-932e-ebb161563271",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_events(raw, pong_results, subject = '', num_trials = 160, filter_events = True):\n",
    "\n",
    "    if subject == '':\n",
    "        print('No input subject!')\n",
    "    \n",
    "    events = mne.find_events(raw, output = 'onset')\n",
    "    \n",
    "    if events.shape[0] != 507:\n",
    "        events = events[1:,:]\n",
    "    \n",
    "    trigs = events[:,0]\n",
    "    \n",
    "    conditions = pong_results.sel(variable = 'cond', subject = subject)\n",
    "    intercepts = pong_results.sel(variable = 'result', subject = subject)\n",
    "    \n",
    "    pcond = conditions == 1\n",
    "    acond = conditions == 0\n",
    "    \n",
    "    negfb = intercepts == -1\n",
    "    posfb = intercepts == 1\n",
    "    \n",
    "    feedback_times = pong_results.sel(variable = 'feedbackTime', subject = subject).interpolate_na('trial', limit = None, method = 'spline')\n",
    "    thresh_times = pong_results.sel(variable = 'threshTime', subject = subject).interpolate_na('trial', limit = None, method = 'spline')\n",
    "    ball_starts = pong_results.sel(variable = 'startTrig0', subject = subject).interpolate_na('trial', limit = None, method = 'spline')\n",
    "    res_array = pong_results.sel(variable = 'result', subject = subject)\n",
    "\n",
    "    tsDiffs = np.diff(trigs)\n",
    "    start_trigs = np.where(tsDiffs <= 25)[0]\n",
    "    end_trigs = start_trigs + 2\n",
    "    \n",
    "    events[start_trigs,2] = 1\n",
    "    events[start_trigs+1,2] = 2\n",
    "    events[end_trigs,2] = 3\n",
    "    sEvents = events[start_trigs]\n",
    "    eEvents = events[end_trigs]\n",
    "    \n",
    "    fb_to_thresh = np.round((feedback_times - thresh_times)* raw.info['sfreq'])\n",
    "    feedbackTimestamps = (fb_to_thresh + events[end_trigs,0][-num_trials:]).to_numpy()\n",
    "    \n",
    "    fbEvents = eEvents[-num_trials:].copy()\n",
    "    fbEvents[:,0] = feedbackTimestamps\n",
    "    fbEvents[-num_trials:,2] = res_array\n",
    "    \n",
    "    bmEvents = sEvents[-num_trials:].copy()\n",
    "    bmEvents[-num_trials:,2] = res_array\n",
    "    \n",
    "    pBMEvs = bmEvents[pcond]\n",
    "    aBMEvs = bmEvents[acond]\n",
    "    \n",
    "    pFBEvs = fbEvents[pcond]\n",
    "    aFBEvs = fbEvents[acond]\n",
    "\n",
    "    if filter_events:\n",
    "        return pBMEvs, aBMEvs, pFBEvs, aFBEvs\n",
    "    else:\n",
    "        return bmEvents, fbEvents, conditions, intercepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b407b8-5272-4fee-ada8-07b857906169",
   "metadata": {},
   "source": [
    "# Preprocessing behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0db4eb3-17c0-42c4-99e2-27e1b7c33b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLead = -0.7\n",
    "maxLag = 0\n",
    "event_label = 'threshTime'\n",
    "\n",
    "session_results_agg = []\n",
    "movement_trials_agg = []\n",
    "agg_movements = []\n",
    "\n",
    "for sub_ind, sub_dir in enumerate(subject_folders):\n",
    "    session_data, movement_data, binned_mvms = process_pong_session(sub_dir, maxLead=maxLead, maxLag=maxLag, event_label=event_label)\n",
    "    session_results_agg.append(session_data)\n",
    "    movement_trials_agg.append(movement_data)\n",
    "    agg_movements.append(binned_mvms)\n",
    "\n",
    "agg_movements = np.array(agg_movements)\n",
    "agg_movements = np.transpose(agg_movements, (1,3,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900b3089-c912-42c4-8514-f2d76babe0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_beh_columns = ['BDP_new', 'BAP_new', 'BDP', 'BAP', 'offset', 'ballX', 'ms',\n",
    " 'ballSpeedX', 'ballSpeedY','text.started', 'startTrig0',\n",
    " 'startTrig1', 'threshTime', 'feedbackTime', 'result', 'cond',\n",
    " 'participant','age', 'gender', 'condOrder','Number']\n",
    "\n",
    "session_dims = ('variable', 'trial', 'subject')\n",
    "session_coords = {'variable': relevant_beh_columns, 'subject': subjects}\n",
    "\n",
    "results_array = []\n",
    "\n",
    "for sInd, session_results in enumerate(session_results_agg):    \n",
    "    df = session_results[relevant_beh_columns].copy()\n",
    "    subj = df.loc[0,'participant']\n",
    "    mapd = {'n': -1, 'p': 1, 'a-p': 0.1, 'p-a': 1.0, 'male' : 1, 'female' : 2, subj: int(subj.split('p')[-1])}\n",
    "    df = df.replace(mapd).to_numpy()\n",
    "    results_array.append(df)\n",
    "results_array = np.transpose(np.array(results_array), (2,1,0))\n",
    "results_array=xr.DataArray(results_array, dims = session_dims, coords = session_coords)\n",
    "results_array.to_netcdf(preprocess_dir + 'agg_pong_results.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce188d7a-28b3-420e-9f28-c86b71b1f2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvm_data_dims = ('time', 'trial', 'source', 'subject')\n",
    "mvm_data_coords = {'source': ['movement', 'timestamp', 'ball_y', 'ball_x'], 'subject': subjects}\n",
    "mvm_data_attrs = {'max_lead' : maxLead, 'max_lag' : maxLag, 'center_event': event_label}\n",
    "\n",
    "movement_array = xr.DataArray(agg_movements, dims = mvm_data_dims, coords = mvm_data_coords, attrs = mvm_data_attrs)\n",
    "movement_array.to_netcdf(preprocess_dir + 'agg_pong_movement_' + event_label + '_lock.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8589484-f940-4f7c-a7ea-865ccf31cc1a",
   "metadata": {},
   "source": [
    "# Loading Beh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a4e103-1338-4d58-a18f-d6a4e461078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_string = 'EEG/'\n",
    "\n",
    "\n",
    "mapped_dict = {-1: 'n', 1: 'p', 0.1: 'a-p', 1.0: 'p-a', 1: 'Male', 2: 'Female'}\n",
    " \n",
    "pong_results = xr.load_dataarray(parent_preprocess_dir + 'agg_pong_results.nc').load()\n",
    "pong_movement_raw = xr.load_dataarray(parent_preprocess_dir + 'agg_pong_movement_' + event_label + '_lock.nc').load()\n",
    "\n",
    "f_order = 2\n",
    "low_cut = 12\n",
    "lowpass = signal.butter(f_order, low_cut, fs = 120, btype = 'lp', output ='sos') \n",
    "pong_movement_data = signal.sosfiltfilt(lowpass, pong_movement_raw.sel(source='movement'), axis = 0)\n",
    "pong_movement = pong_movement_raw.copy()\n",
    "pong_movement[:, :, 0, :] = pong_movement_data\n",
    "\n",
    "conditions = pong_results.sel(variable = 'cond')\n",
    "intercepts = pong_results.sel(variable = 'result')\n",
    "\n",
    "pcond = conditions == 1\n",
    "acond = conditions == 0\n",
    "\n",
    "negfb = intercepts == -1\n",
    "posfb = intercepts == 1\n",
    "\n",
    "subject_gens = pong_results.sel(variable = 'gender', trial = 0).to_numpy()\n",
    "gen_list = [mapped_dict[gen] for gen in subject_gens]\n",
    "\n",
    "num_subjects = len(subjects)\n",
    "male_subjects = subject_gens == 1\n",
    "female_subjects = subject_gens == 2\n",
    "\n",
    "subject_groups = [female_subjects, male_subjects]\n",
    "subject_group_names = ['Female', 'Male']\n",
    "num_subject_groups = len(subject_groups)\n",
    "subject_group_dict = {subject_group_names[ind]: subject_groups[ind] for ind in range(num_subject_groups)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e0b204-6929-492f-a30f-9f899efe12d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_beh = np.zeros(len(subjects))\n",
    "a_beh = np.zeros(len(subjects))\n",
    "\n",
    "for sInd, subj in enumerate(subjects):\n",
    "    \n",
    "    if sInd == 0:\n",
    "        labels = ['Presence', 'Absence']\n",
    "    else:\n",
    "        labels = ['', '']\n",
    "    \n",
    "    sub_bs = pong_results.sel(subject = subj, variable = 'ms')\n",
    "    sub_bap = pong_results.sel(subject = subj, variable = 'BAP_new')\n",
    "    sub_bdp = pong_results.sel(subject = subj, variable = 'BDP_new')\n",
    "    sub_bap[sub_bap == 0] = 1\n",
    "        \n",
    "    sub_movement = np.abs(pong_movement.sel(subject = subj, source = 'movement')/sub_bap)\n",
    "    \n",
    "    sub_speed = np.gradient(sub_movement, axis = 0)\n",
    "    sub_speed = xr.DataArray(sub_speed, coords = sub_movement.coords, dims = sub_movement.dims)\n",
    "\n",
    "    stable_trials = ~(sub_movement[0,:] >= sub_movement[-1,:])    \n",
    "\n",
    "    nfb = negfb.sel(subject = subj)\n",
    "    pfb = posfb.sel(subject = subj)\n",
    "    \n",
    "    pres = pcond.sel(subject = subj)\n",
    "    abse = acond.sel(subject = subj)\n",
    "\n",
    "    p_tr = pres & stable_trials\n",
    "    a_tr = abse & stable_trials\n",
    "        \n",
    "    p_sum = (p_tr & pfb).sum('trial')\n",
    "    a_sum = (p_tr & pfb).sum('trial')\n",
    "\n",
    "    vel_metric = sub_speed\n",
    "    \n",
    "    p_met = vel_metric.sel(trial = p_tr).mean('time').mean('trial')\n",
    "    a_met = vel_metric.sel(trial = a_tr).mean('time').mean('trial')\n",
    "   \n",
    "    p_beh[sInd] = p_met\n",
    "    a_beh[sInd] = a_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd4cc7-a328-4ff3-91d0-7e3c47805658",
   "metadata": {},
   "outputs": [],
   "source": [
    "beh_norm_concat = preprocessing.MinMaxScaler().fit_transform(np.concatenate((p_beh, a_beh)).reshape(-1,1)).ravel()\n",
    "p_beh = beh_norm_concat[:num_subjects]\n",
    "a_beh = beh_norm_concat[num_subjects:]\n",
    "\n",
    "beh_ratio = p_beh/(p_beh+a_beh) * 100\n",
    "\n",
    "beh_ratio_groups = np.zeros((2,14))\n",
    "beh_ratio_groups[0,:] = beh_ratio[female_subjects]\n",
    "beh_ratio_groups[1,:male_subjects.sum()] = beh_ratio[male_subjects]\n",
    "beh_ratio_array = xr.DataArray(beh_ratio_groups, dims = ('group', 'subject'), coords = {'group': ['Female', 'Male']})\n",
    "beh_ratio_array.to_netcdf(parent_preprocess_dir + '/beh_ratio_array.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caf6572-fc20-4b4f-925f-8f3bff0bb50f",
   "metadata": {},
   "source": [
    "# Template artifact components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba99f565-f5f7-448a-822b-b20166a72ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite_templates = True\n",
    "\n",
    "if overwrite_templates:\n",
    "\n",
    "    sInd = 0\n",
    "    data_path = poly5_dirs[sInd]\n",
    "    subject_name = subjects[sInd]\n",
    "    subject_folder = subject_folders[sInd]\n",
    "    \n",
    "    data = Poly5Reader(data_path)\n",
    "    raw = data.read_data_MNE()\n",
    "    \n",
    "    raw.drop_channels(['Counter 2power24', 'TRIGGERS'])\n",
    "    \n",
    "    channels = np.array(raw.ch_names)\n",
    "    eegChs = channels[:64]\n",
    "    miscChs = channels[64:]\n",
    "    chTypes = {}\n",
    "    for channel in channels:\n",
    "        if channel not in miscChs:\n",
    "            chTypes[channel] = 'eeg'\n",
    "        elif channel == 'STATUS':\n",
    "            chTypes[channel] = 'stim'\n",
    "    \n",
    "    raw.set_channel_types(chTypes)\n",
    "    raw.set_montage('standard_1005')\n",
    "    \n",
    "    # Removing & Interpolating bad channels\n",
    "    print('Removing bad channels')\n",
    "    bmEvents, fbEvents, conditions, intercepts = calculate_events(raw, pong_results, subject=subject_name, filter_events=False)\n",
    "    \n",
    "    raw.info['bads'] = []\n",
    "    epoch_events = bmEvents\n",
    "    epoch_ids = {'Interception': 1, 'Miss': -1}\n",
    "    tmin = -0.5\n",
    "    tmax = 1\n",
    "    \n",
    "    raw_epochs = mne.Epochs(raw, epoch_events, epoch_ids, tmin, tmax,\n",
    "                    baseline=(None, -0.2), reject=None,\n",
    "                    verbose=False, detrend=1, preload=True)\n",
    "    picks = mne.pick_types(raw_epochs.info, eeg=True, include=[], exclude=[])\n",
    "    ransac = Ransac(verbose=False, picks=picks, n_jobs=8)\n",
    "    raw_epochs_clean = ransac.fit_transform(raw_epochs)\n",
    "    \n",
    "    raw.info['bads'] = ransac.bad_chs_\n",
    "    raw.interpolate_bads()\n",
    "    raw.set_eeg_reference(ref_channels='average')\n",
    "    \n",
    "    # ICA computation\n",
    "    print('Computing ICA')\n",
    "    \n",
    "    low_cut = 1\n",
    "    high_cut = 45\n",
    "    n_jobs = 8\n",
    "    n_comp = 30\n",
    "    stop = 900\n",
    "    method = 'fir'\n",
    "    \n",
    "    raw.filter(low_cut, high_cut, n_jobs='cuda', method=method)\n",
    "    \n",
    "    ica = ICA(n_components=n_comp, method='fastica', max_iter='auto', random_state=97)\n",
    "    icaEvts = mne.make_fixed_length_events(raw, start=25, stop=stop)\n",
    "    icaEpochs = mne.Epochs(raw, events=icaEvts, baseline=None)\n",
    "    reject = get_rejection_threshold(icaEpochs);\n",
    "    ica.fit(icaEpochs, reject=reject)\n",
    "    \n",
    "    ica.plot_components(picks=[0,2]);\n",
    "    \n",
    "    ica_comps = ica.get_components()\n",
    "    eog_template = ica_comps[:,0].squeeze()\n",
    "    sac_template = ica_comps[:,2].squeeze()\n",
    "    \n",
    "    ica_template = np.concatenate((eog_template.reshape(-1,1), sac_template.reshape(-1,1)), axis = 1)\n",
    "    \n",
    "    ica_template = xr.DataArray(ica_template, dims = ('region', 'template'), coords = {'template': ['blink', 'saccade']})\n",
    "    ica_template.to_netcdf(preprocess_dir + 'ica_component_templates.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6090fff-8214-4f71-9da8-fc1d9623148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ICA templates necessary for artifact removal in the following steps\n",
    "template_array = xr.load_dataarray(preprocess_dir + 'ica_component_templates.nc').load()\n",
    "blink_template = template_array.sel(template = 'blink').to_numpy()\n",
    "saccade_template = template_array.sel(template = 'saccade').to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014bf374-d4dc-40aa-a2d4-bb3ceb1fc598",
   "metadata": {},
   "source": [
    "# Process raw EEG files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1193e0-166f-4aae-a15a-ee3f352f716a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "\n",
    "for sInd in trange(len(subject_folders)):\n",
    "    \n",
    "    data_path = poly5_dirs[sInd]\n",
    "    subject_name = subjects[sInd]\n",
    "    subject_folder = subject_folders[sInd]\n",
    "    \n",
    "    if overwrite:\n",
    "        process_raw_tmsi(data_path=data_path, subject_name=subject_name,\n",
    "                        subject_folder=subject_folder, pong_results=pong_results,\n",
    "                        check_channel_names=True, overwrite=overwrite)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cea513f-146a-4e1f-9fbc-a01f5b2253df",
   "metadata": {},
   "source": [
    "Getting the directories of all the necessary files in the following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_clean_dirs = glob.glob(measurements_dir + '**/*_raw_clean.fif', recursive=True)\n",
    "inv_operator_dirs = glob.glob(measurements_dir + '**/*_inv.fif', recursive=True)\n",
    "fwd_operator_dirs = glob.glob(measurements_dir + '**/*_fwd.fif', recursive=True)\n",
    "noise_cov_dirs = glob.glob(measurements_dir + '**/*_cov.fif', recursive=True)\n",
    "ica_dirs = glob.glob(measurements_dir + '**/*_ica.fif', recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26490e10-4973-4c21-b107-0c47dc9a9d1e",
   "metadata": {},
   "source": [
    "# Experimental setup figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f4bbcb-6cb2-45f3-af91-40646378aeeb",
   "metadata": {},
   "source": [
    "## ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc027f1-f310-4834-a345-fdd9f9949cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2)\n",
    "\n",
    "ica.plot_components(picks=[0,2], axes=axes);\n",
    "fig.tight_layout()\n",
    "fig.savefig(fig_save_loc + save_string + 'ica_templates.svg', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aeaee9-46f3-4c6f-942a-fc6815eefd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sInd = 20\n",
    "subject_name = subjects[sInd]\n",
    "\n",
    "low_cut = 2\n",
    "high_cut = 45\n",
    "n_jobs = 8\n",
    "n_comp = 30\n",
    "stop = 900\n",
    "method = 'fir'\n",
    "\n",
    "raw = mne.io.read_raw_fif(raw_clean_dirs[sInd], preload=True)\n",
    "raw.filter(low_cut, high_cut, n_jobs='cuda', method=method)\n",
    "\n",
    "bmEvents, fbEvents, conditions, intercepts = calculate_events(raw, pong_results, subject=subject_name, filter_events=False)\n",
    "\n",
    "epoch_events = bmEvents\n",
    "epoch_ids = {'Interception': 1, 'Miss': -1}\n",
    "baseline_tmax=-0.2\n",
    "tmin = -0.5\n",
    "tmax = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833205b1-042a-4d7f-bc89-0e18eb66a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_epochs = mne.Epochs(raw, epoch_events, epoch_ids, tmin, tmax,\n",
    "                baseline=(None, baseline_tmax), reject=None,\n",
    "                verbose=False, detrend=0, preload=True)\n",
    "raw_epochs.crop(tmin=0, tmax=tmax)\n",
    "\n",
    "fig = raw_epochs.average().plot();\n",
    "ax = fig.gca()\n",
    "fig.set_frameon(False)\n",
    "ax.set_frame_on(False)\n",
    "ax.tick_params(length=0, size=0)\n",
    "\n",
    "fig.savefig(fig_save_loc + save_string + 'evoked_template.svg', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7036e807-4332-4412-96bb-1b11c0a8efb0",
   "metadata": {},
   "source": [
    "## PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aada50c1-9a89-415c-8f75-a246432f62b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_min = None\n",
    "baseline_max = -0.2\n",
    "baseline = (baseline_min, baseline_max)\n",
    "tmin_epoch = -0.5\n",
    "tmax_epoch = 1\n",
    "\n",
    "detrend = 0\n",
    "decim = 8\n",
    "n_jobs = 8\n",
    "\n",
    "windows = ['hann', 'hamming', 'blackman', 'flattop', 'boxcar']\n",
    "w_ind = 0\n",
    "window = windows[w_ind]\n",
    "n_fft = 1000\n",
    "n_per_seg = 200\n",
    "# n_per_seg = n_fft//2\n",
    "fmin = 2; fmax = 30;\n",
    "\n",
    "average = True; dB = False; remove_dc = False;\n",
    "\n",
    "subject_psds = []\n",
    "subject_psds_evoked = []\n",
    "mean_source_psd = []\n",
    "source_sensor_psd = []\n",
    "\n",
    "for s_ind, subject in enumerate(subjects):\n",
    "\n",
    "    message = f\"Subject {subject}: Processing...\"\n",
    "    clear_output(wait=False)\n",
    "    display(message)\n",
    "    \n",
    "    raw = mne.io.read_raw_fif(raw_clean_dirs[s_ind], preload = True)\n",
    "    raw.set_eeg_reference(projection=False)\n",
    "    raw.filter(fmin, fmax, n_jobs='cuda')\n",
    "    \n",
    "    pBMEvs, aBMEvs, pFBEvs, aFBEvs = calculate_events(raw, pong_results, subject=subject, filter_events=True)\n",
    "    \n",
    "    bmEvs, _, _, _ = calculate_events(raw, pong_results, subject=subject, filter_events=False)\n",
    "    \n",
    "    raw_epochs = mne.Epochs(raw, bmEvs, None, picks = 'eeg', tmax=tmax_epoch, tmin=tmin_epoch, baseline=baseline, preload=True, detrend=detrend, decim=decim);\n",
    "    raw_evoked = raw_epochs.average()\n",
    "        \n",
    "    psd = raw_epochs.compute_psd(fmin=fmin, fmax=fmax, proj=False, n_jobs=n_jobs, method='welch', remove_dc=remove_dc,\n",
    "                         window=window, n_fft=n_fft, n_per_seg=n_per_seg);\n",
    "\n",
    "    psd_evoked = raw_evoked.compute_psd(fmin=fmin, fmax=fmax, proj=False, n_jobs=n_jobs, method='welch', remove_dc=remove_dc,\n",
    "                         window=window, n_fft=n_fft, n_per_seg=n_per_seg);\n",
    "\n",
    "    subject_psds.append(psd)\n",
    "    subject_psds_evoked.append(psd_evoked)\n",
    "    \n",
    "    del(raw, raw_epochs); gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5d32d4-d54f-4cda-850a-aa9b61e2b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,a = plt.subplots(3, 9, figsize = (20,5))\n",
    "\n",
    "dB = False\n",
    "loglog = False\n",
    "\n",
    "if loglog:\n",
    "    yticks = [1e0]\n",
    "    xticks = [1e0, 1e1]\n",
    "else:\n",
    "    yticks = [0.5, 2]\n",
    "    xticks = [0, 10, 20, 30]\n",
    "\n",
    "\n",
    "for a_ind, ax in enumerate(a.ravel()):\n",
    "\n",
    "    psd = subject_psds[a_ind]\n",
    "    \n",
    "    psd.plot(average=True, dB=dB, axes=ax, );\n",
    "\n",
    "    ax.set_title(str(subjects[a_ind]))\n",
    "    \n",
    "    if loglog:\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_xscale('log')\n",
    "    \n",
    "    modify_axis_spines(ax, which=['x', 'y'], xticks=xticks, yticks=yticks)\n",
    "    \n",
    "if dB:\n",
    "    xlabel = r\"$\\mu V$/Hz$^2$\"\n",
    "else:\n",
    "    xlabel = r\"$\\sqrt{\\mu V}$/Hz\"\n",
    "\n",
    "fontsize = 12\n",
    "\n",
    "f.supylabel(xlabel, x=0.01, fontsize=fontsize)\n",
    "f.supxlabel('Frequency (Hz)', y=0.02, fontsize=fontsize)\n",
    "f.tight_layout()\n",
    "f.savefig(fig_save_loc + save_string + 'psd_all.svg', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea90403-ff02-4ef4-a63f-b6e6ea6258b6",
   "metadata": {},
   "source": [
    "# Extract source timecourse & MNE-Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93b8d7c-b83e-4be9-9fc9-3c09192b5d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "parc = 'Schaefer2018_400Parcels_7Networks_order'\n",
    "fs_dir = ''\n",
    "fs_label_dir = ''\n",
    "labels = mne.read_labels_from_annot('fsaverage', parc=parc, regexp='7Network', subjects_dir=fs_label_dir)\n",
    "label_names = [label.name for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5223deb-203f-4dbc-8733-ed5e4a9e744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data parameters\n",
    "task_conditions = ['Presence', 'Absence']\n",
    "\n",
    "n_jobs = 8\n",
    "decim = 8\n",
    "detrend = 0\n",
    "baseline_min = None\n",
    "baseline_max = 0\n",
    "baseline = (baseline_min, baseline_max)\n",
    "tmin_epoch = -0.2\n",
    "tmax_epoch = 0.5\n",
    "fmin, fmax = 8, 12\n",
    "\n",
    "mode = 'multitaper'\n",
    "\n",
    "# lambda2 epochs/evoked\n",
    "snr = 1.0\n",
    "lambda2 = 1.0 / snr**2\n",
    "\n",
    "snr_evoked = 3.0\n",
    "lambda2_evoked = 1.0 / snr_evoked**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f98187-47f5-45c7-847d-1a4a64f9a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = subjects[0]\n",
    "print(subj)\n",
    "\n",
    "raw = mne.io.read_raw_fif(raw_clean_dirs[sInd], preload = True)\n",
    "raw.set_eeg_reference(projection=True)\n",
    "raw.filter(fmin, fmax, n_jobs='cuda')\n",
    "\n",
    "pBMEvs, aBMEvs, pFBEvs, aFBEvs = calculate_events(raw, pong_results, subject=subj, filter_events=True)\n",
    "\n",
    "p_events = pBMEvs    \n",
    "p_epochs = mne.Epochs(raw, p_events, None, picks='eeg', tmax=tmax_epoch, tmin=tmin_epoch, baseline=baseline, preload=True, decim=decim, detrend=detrend)\n",
    "p_evoked = p_epochs.average()\n",
    "p_epochs.crop(baseline_max, tmax_epoch, include_tmax=True)\n",
    "\n",
    "num_subjects = len(subjects)\n",
    "num_conds = len(task_conditions)\n",
    "num_timepoints = p_epochs.times.shape[0]\n",
    "num_timepoints_evoked = p_evoked.times.shape[0]\n",
    "num_trials = 80\n",
    "num_labels = len(labels)\n",
    "\n",
    "del(raw);gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ecdb30-11f7-44b3-ab17-db24d3c7d5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize source timecourse array\n",
    "source_epochs = xr.DataArray(np.zeros((num_conds, num_timepoints, num_trials, num_labels, num_subjects)),\n",
    "                             dims=('condition', 'time', 'trial', 'label', 'subject'), coords={'condition':task_conditions, 'label':label_names, 'subject':subjects})\n",
    "source_evoked = xr.DataArray(np.zeros((num_conds, num_timepoints_evoked, num_labels, num_subjects)),\n",
    "                             dims=('condition', 'time', 'label', 'subject'), coords={'condition':task_conditions, 'label':label_names, 'subject':subjects})\n",
    "source_snr = source_evoked.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b5764-b3b7-4295-8400-ff6495fd825a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sInd in trange(num_subjects):    \n",
    "    \n",
    "    subj = subjects[sInd]\n",
    "    \n",
    "    message = f\"Subject {subj}: Extracting source timecourse...\"\n",
    "    clear_output(wait=False)\n",
    "    display(message)\n",
    "    \n",
    "    raw = mne.io.read_raw_fif(raw_clean_dirs[sInd], preload = True)\n",
    "    raw.set_eeg_reference(projection=True)\n",
    "    raw.filter(fmin, fmax, n_jobs='cuda')\n",
    "    \n",
    "    pBMEvs, aBMEvs, pFBEvs, aFBEvs = calculate_events(raw, pong_results, subject = subj, filter_events=True)\n",
    "    \n",
    "    p_events = pBMEvs\n",
    "    a_events = aBMEvs\n",
    "    \n",
    "    p_epochs = mne.Epochs(raw, p_events, None, picks='eeg', tmax=tmax_epoch, tmin=tmin_epoch, baseline=baseline, preload=True, decim=decim, detrend=detrend)\n",
    "    a_epochs = mne.Epochs(raw, a_events, None, picks='eeg', tmax=tmax_epoch, tmin=tmin_epoch, baseline=baseline, preload=True, decim=decim, detrend=detrend)\n",
    "    \n",
    "    p_evoked = p_epochs.average()\n",
    "    a_evoked = a_epochs.average()\n",
    "\n",
    "    p_epochs.crop(baseline_max, tmax_epoch)\n",
    "    a_epochs.crop(baseline_max, tmax_epoch)\n",
    "    \n",
    "    inv = mne.minimum_norm.read_inverse_operator(inv_operator_dirs[sInd])\n",
    "    fwd = mne.read_forward_solution(fwd_operator_dirs[sInd])\n",
    "    cov = mne.read_cov(noise_cov_dirs[sInd])\n",
    "    src = inv['src']\n",
    "\n",
    "    p_stc_epochs = mne.minimum_norm.apply_inverse_epochs(p_epochs, inv, lambda2=lambda2, method=\"MNE\")\n",
    "    a_stc_epochs = mne.minimum_norm.apply_inverse_epochs(a_epochs, inv, lambda2=lambda2, method=\"MNE\")\n",
    "    \n",
    "    p_ts_epochs = np.array(mne.extract_label_time_course(p_stc_epochs, labels, src, mode='mean_flip'))\n",
    "    a_ts_epochs = np.array(mne.extract_label_time_course(a_stc_epochs, labels, src, mode='mean_flip'))\n",
    "    \n",
    "    p_stc_evoked = mne.minimum_norm.apply_inverse(p_evoked, inv, lambda2=lambda2_evoked, method='MNE')\n",
    "    a_stc_evoked = mne.minimum_norm.apply_inverse(a_evoked, inv, lambda2=lambda2_evoked, method='MNE')\n",
    "    \n",
    "    p_ts_evoked = mne.extract_label_time_course(p_stc_evoked, labels, src, mode='mean_flip')\n",
    "    a_ts_evoked = mne.extract_label_time_course(a_stc_evoked, labels, src, mode='mean_flip')\n",
    "\n",
    "    p_snr_stc = p_stc_evoked.estimate_snr(p_evoked.info, fwd, cov)\n",
    "    a_snr_stc = a_stc_evoked.estimate_snr(a_evoked.info, fwd, cov)\n",
    "\n",
    "    p_snr_ts = mne.extract_label_time_course(p_snr_stc, labels, src, mode='mean_flip')\n",
    "    a_snr_ts = mne.extract_label_time_course(a_snr_stc, labels, src, mode='mean_flip')\n",
    "    \n",
    "    source_epochs[0, :, :, :, sInd] = p_ts_epochs.T.swapaxes(1,2)\n",
    "    source_epochs[1, :, :, :, sInd] = a_ts_epochs.T.swapaxes(1,2)\n",
    "\n",
    "    source_evoked[0, :, :, sInd] = p_ts_evoked.T\n",
    "    source_evoked[1, :, :, sInd] = a_ts_evoked.T\n",
    "\n",
    "    source_snr[0, :, :, sInd] = p_snr_ts.T\n",
    "    source_snr[1, :, :, sInd] = a_snr_ts.T\n",
    "\n",
    "    del(raw, p_epochs, a_epochs, p_evoked, a_evoked, p_stc_epochs, a_stc_epochs, p_stc_evoked, a_stc_evoked, p_snr_stc, a_snr_stc, p_snr_ts, a_snr_ts);gc.collect()\n",
    "    del(raw, p_epochs, a_epochs, p_evoked, a_evoked, p_snr_stc, a_snr_stc, p_snr_ts, a_snr_ts);gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5db8231-520d-4a38-80c9-22a7416a2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_epochs.to_netcdf(parent_preprocess_dir + 'source_epochs_7Networks_bm_full.nc')\n",
    "source_evoked.to_netcdf(parent_preprocess_dir + 'source_evoked_7Networks_bm_full.nc')\n",
    "source_snr.to_netcdf(parent_preprocess_dir + 'source_snr_7Networks_bm_full.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9de9448-8e59-4112-ae9a-dff708c759bc",
   "metadata": {},
   "source": [
    "# Load source Timecourse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b358915-408e-47ae-8623-dfed3af9e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_epochs = xr.load_dataarray(parent_preprocess_dir + 'source_epochs_7Networks_bm_full.nc')\n",
    "source_evoked = xr.load_dataarray(parent_preprocess_dir + 'source_evoked_7Networks_bm_full.nc')\n",
    "source_snr = xr.load_dataarray(parent_preprocess_dir + 'source_snr_7Networks_bm_full.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43cd201-0c9e-4bac-90b9-db9a71988e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = source_epochs.label.to_numpy()\n",
    "\n",
    "yeo_networks = np.array(['DorsAttn', 'SalVentAttn', 'SomMot', 'Vis', 'Cont' ,'Default', 'Limbic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0203ef02-cb5d-4995-aa34-20b47a4f04b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parc = 'Schaefer2018_400Parcels_7Networks_order'\n",
    "fs_label_dir = ''\n",
    "\n",
    "network_label_dict = {n_name: np.array([label.name for label in mne.read_labels_from_annot('fsaverage', parc=parc, regexp=n_name, subjects_dir=fs_label_dir)], dtype=object)\n",
    "                      for n_name in yeo_networks}\n",
    "\n",
    "all_labels = mne.read_labels_from_annot('fsaverage', parc=parc, regexp='7Network', subjects_dir=fs_label_dir)\n",
    "all_label_names = np.array([label.name for label in all_labels], dtype=object)\n",
    "\n",
    "network_dimensions = {n_name: len(n_labels) for n_name, n_labels in network_label_dict.items()}\n",
    "network_names = list(network_label_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306d4139-bca5-42e2-be95-899f2454eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of dimensions\n",
    "fc_sources = ['epochs', 'evoked']\n",
    "task_conditions = ['Presence', 'Absence']\n",
    "num_subjects = len(subjects)\n",
    "num_conds = len(task_conditions)\n",
    "num_labels = len(label_names)\n",
    "num_fc_sources = len(fc_sources)\n",
    "num_networks = len(network_names)\n",
    "num_timepoints = source_epochs.time.size\n",
    "\n",
    "fc_dims = ('subject', 'condition', 'source', 'network', 'label_1', 'label_2')\n",
    "fc_coords = {'subject':subjects, 'condition': task_conditions, 'source': fc_sources, 'network': network_names, 'label_1': label_names, 'label_2': label_names}\n",
    "fc_attrs = network_dimensions\n",
    "fc_array_emp = xr.DataArray(np.zeros((num_subjects, num_conds, num_fc_sources, num_networks, num_labels, num_labels)), dims=fc_dims, coords=fc_coords, attrs=fc_attrs)\n",
    "fc_array_emp.attrs = network_dimensions\n",
    "\n",
    "fc_array_emp_global = xr.DataArray(np.zeros((num_subjects, num_conds, num_fc_sources, num_labels, num_labels)),\n",
    "                                   dims=('subject', 'condition', 'source', 'label_1', 'label_2'),\n",
    "                                   coords={'subject':subjects, 'condition': task_conditions, 'source': fc_sources, 'label_1': label_names, 'label_2': label_names})\n",
    "\n",
    "snr_dims = ('subject', 'condition', 'time', 'network')\n",
    "snr_coords = {'subject':subjects, 'condition': task_conditions, 'network': network_names}\n",
    "snr_array = xr.DataArray(np.zeros((num_subjects, num_conds, source_snr.time.size, num_networks)), dims=snr_dims, coords=snr_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c613060-dc20-441e-959b-8d1ef0b8d6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_epochs = source_epochs.mean('trial').copy()\n",
    "mean_epochs = mean_epochs/mean_epochs.max(('condition', 'time', 'label'))\n",
    "\n",
    "source_evoked_norm = source_evoked.copy()/source_evoked.max(('condition', 'time', 'label'))\n",
    "source_snr_norm = source_snr.copy()/source_snr.max(('condition', 'time', 'label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff967d54-6c27-4812-a00b-b9e422deee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s_ind in trange(num_subjects):\n",
    "    \n",
    "    subject=subjects[s_ind]\n",
    "    \n",
    "    message = f\"Subject {subject}: Computing features...\"\n",
    "    clear_output(wait=False)\n",
    "    display(message)\n",
    "    \n",
    "    for c_ind, condition in enumerate(task_conditions):\n",
    "        \n",
    "        for net_ind, (net_name, net_labels) in enumerate(network_label_dict.items()):\n",
    "\n",
    "            network_dim = network_dimensions[net_name]\n",
    "                  \n",
    "            fc_epochs = compute_FC(mean_epochs.sel(subject=subject, condition=condition, label=net_labels).T.to_numpy(), fc_only=True)\n",
    "            fc_evoked = compute_FC(source_evoked_norm.sel(subject=subject, condition=condition, label=net_labels).T.to_numpy(), fc_only=True)\n",
    "\n",
    "            fc_epochs_global = compute_FC(mean_epochs.sel(subject=subject, condition=condition).T.to_numpy(), fc_only=True)\n",
    "            fc_evoked_global = compute_FC(source_evoked_norm.sel(subject=subject, condition=condition).T.to_numpy(), fc_only=True)\n",
    "            \n",
    "            # Assigning computed FC to arrays\n",
    "            fc_array_emp[s_ind, c_ind, 0, net_ind, :network_dim, :network_dim] = fc_epochs\n",
    "            fc_array_emp[s_ind, c_ind, 1, net_ind, :network_dim, :network_dim] = fc_evoked\n",
    "\n",
    "            fc_array_emp_global[s_ind, c_ind, 0, :, :] = fc_epochs_global\n",
    "            fc_array_emp_global[s_ind, c_ind, 1, :, :] = fc_evoked_global\n",
    "            \n",
    "            snr_array[s_ind, c_ind, :, net_ind] = source_snr_norm.sel(subject=subject, condition=condition, label=net_labels).mean('label').T.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bd653a-8967-4484-a1a3-9c499a4fff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_array_emp_global.to_netcdf(parent_preprocess_dir + 'source_fc_global.nc')\n",
    "fc_array_emp.to_netcdf(parent_preprocess_dir + 'source_fc_7Networks_norm_full.nc')\n",
    "snr_array.to_netcdf(parent_preprocess_dir + 'source_snr_7Networks_norm_full.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4494bae1-1ded-46b6-a8f8-7bdec9fb5e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_max = snr_array.mean('time')\n",
    "snr_max = snr_max.rename(subject='group')\n",
    "snr_max.coords['group'] = gen_list\n",
    "\n",
    "snr_max_df = snr_max.to_dataframe(name='value').reset_index()\n",
    "snr_max_df_reindexed = snr_max_df.set_index('group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f227ed38-1b80-4551-90cd-9e743bdfb61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = 0.1\n",
    "width_viol = 0.5\n",
    "orient = 'v'\n",
    "alpha = .99\n",
    "dodge = True\n",
    "pointplot = False\n",
    "move = 0.2\n",
    "point_size = 0\n",
    "cut = 0.5\n",
    "scale = 'area'\n",
    "width_box = 0.5\n",
    "line_width = 1.5\n",
    "saturation = 1\n",
    "\n",
    "absence_color, presence_color = 'crimson', 'dodgerblue'\n",
    "palette = {'Presence': presence_color, 'Absence': absence_color}    \n",
    "stat_list = [((net, 'Presence'), (net, 'Absence')) for net in yeo_networks]\n",
    "\n",
    "for group in subject_group_names:\n",
    "\n",
    "    group_distribution = snr_max_df_reindexed.loc[group]\n",
    "       \n",
    "    f, ax = plt.subplots(figsize=(8,4))\n",
    "\n",
    "    flierprops = dict(marker='o', markerfacecolor='None', markersize=0,  markeredgecolor='black')\n",
    "    \n",
    "    violins = sns.boxplot(data=group_distribution, x='network', y='value', hue='condition', width=0.7, flierprops=flierprops,\n",
    "                   palette=palette, saturation=0.8, dodge=True, ax=ax, linewidth=2, showcaps=False, whis=1,);\n",
    "    \n",
    "    annotator = Annotator(ax, stat_list, data=group_distribution, x = 'network', y = 'value', hue='condition', verbose=False);\n",
    "    annotator.configure(test='Kruskal', text_format='star', loc='outside', line_width = line_width, color='#484848');\n",
    "    annotator.apply_and_annotate();\n",
    "    \n",
    "    violins.legend_.remove()\n",
    "    \n",
    "    ax.tick_params(axis='y', which='major', labelsize=16)\n",
    "    ax.tick_params(axis='x', which='major', labelsize=16, length = 0)\n",
    "    # modify_axis_spines(ax, which = ['y'], yticks = np.arange(100,115, 5))\n",
    "    ax.set_xlabel('Network',size = 20, labelpad = 12)\n",
    "    ax.set_ylabel(r'$SNR$',size = 20, labelpad = 12)\n",
    "    f.legend(frameon=False, bbox_to_anchor = (1.15,1), fontsize = 12)\n",
    "    f.tight_layout()\n",
    "    f.savefig(fig_save_loc + save_string + 'EEG_SNR_boxs_7Networks_' + group + '.svg', transparent = True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091ace5b-1054-4085-8209-d25d1537664c",
   "metadata": {},
   "source": [
    "# Load All Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4137e6a2-c3d0-4aac-bbe3-52dfd5f95d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_array_emp = xr.load_dataarray(parent_preprocess_dir + 'source_fc_7Networks_norm_full.nc').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db40b74b-28b0-4365-980c-166204e92985",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_conditions = fc_array_emp.condition.to_numpy()\n",
    "fc_sources = fc_array_emp.source.to_numpy()\n",
    "network_dimensions = fc_array_emp.attrs\n",
    "\n",
    "num_subjects = len(subjects)\n",
    "num_sources = len(fc_sources)\n",
    "num_labels = len(fc_array_emp.label_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69562dba-b417-45db-b537-b7ec804546aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tril_label_mask = np.tri(num_labels, num_labels, dtype=bool)\n",
    "tril_time_mask = np.tri(num_timepoints, num_timepoints, dtype=bool)\n",
    "\n",
    "fc_emp_upper = fc_array_emp.to_numpy()\n",
    "fc_emp_upper[:, :, :, :, tril_label_mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fa20c2-a29d-4070-8aae-4e094ceda9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_names = fc_array_emp.dims[:-2]\n",
    "vfc_coords = {k:list(v.to_numpy()) for k,v in fc_array_emp.coords.items() if k in dim_names}\n",
    "\n",
    "op_axes = (-2,-1)\n",
    "fc_emp_sum = xr.DataArray(np.zeros(fc_array_emp.shape[:-2]), dims=dim_names, coords=vfc_coords)\n",
    "fc_emp_avg = fc_emp_sum.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fd735f-3853-4202-a779-6a8cdd28ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s_ind in range(num_subjects):\n",
    "    \n",
    "    subject=subjects[s_ind]\n",
    "    \n",
    "    for c_ind, condition in enumerate(task_conditions):\n",
    "        \n",
    "        for net_ind, (net_name, net_labels) in enumerate(network_label_dict.items()):\n",
    "\n",
    "            network_dim = network_dimensions[net_name]\n",
    "    \n",
    "            for fc_ind, fc_source in enumerate(fc_sources):\n",
    "                \n",
    "                sel_fc = fc_emp_upper[s_ind, c_ind, fc_ind, net_ind, :network_dim, :network_dim]\n",
    "\n",
    "                fc_emp_sum[s_ind, c_ind, fc_ind, net_ind] = sel_fc.sum()\n",
    "                fc_emp_avg[s_ind, c_ind, fc_ind, net_ind] = sel_fc.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a554e738-b82e-4a63-9428-ca86f4510355",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_measures = {'sum_fc': fc_emp_sum, 'avg_fc': fc_emp_avg}\n",
    "measure_names = list(emp_measures.keys())\n",
    "\n",
    "nratio_dims = ('group', 'subject', 'source', 'network', 'measure')\n",
    "nratio_coords = dict(group=subject_group_names, network=network_names, measure=measure_names)\n",
    "neu_ratio_array = xr.DataArray(np.zeros((num_subject_groups, 14, num_sources, num_networks, len(measure_names))), dims=nratio_dims, coords=nratio_coords) \n",
    "\n",
    "selected_stats = ['pearson_r', 'pearson_p', 'spearman_r', 'spearman_p', 'kendalltau_r', 'kendalltau_p']\n",
    "stat_dims = ('group', 'source', 'network', 'measure', 'stat')\n",
    "stat_coords = dict(group=subject_group_names, source=fc_sources, network=network_names, measure=measure_names, stat=selected_stats)\n",
    "emp_stat_array = xr.DataArray(np.zeros((num_subject_groups, num_sources, num_networks, len(measure_names), len(selected_stats))), dims=stat_dims, coords=stat_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0afef2-4087-4abd-819b-df5e5c30eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g_ind, group_name in enumerate(subject_group_names):\n",
    "\n",
    "    subject_group = subject_group_dict[group_name]\n",
    "    group_length = subject_group.sum()\n",
    "\n",
    "    b_ratio = beh_ratio_array.sel(group = group_name)\n",
    "    b_ratio = b_ratio[:subject_group.sum()].to_numpy()\n",
    "    \n",
    "    for m_ind, m_name in enumerate(measure_names):\n",
    "        \n",
    "        sel_measure = emp_measures[m_name]\n",
    "\n",
    "        p_measure = sel_measure.sel(subject=subject_group, condition='Presence')\n",
    "        a_measure = sel_measure.sel(subject=subject_group, condition='Absence')\n",
    "\n",
    "        n_ratio_agg = p_measure/(p_measure+a_measure)*100\n",
    "        len_sources = n_ratio_agg.shape[1]\n",
    "\n",
    "        neu_ratio_array[g_ind, :group_length, :len_sources, :, m_ind] = n_ratio_agg\n",
    "\n",
    "        for fc_ind in range(len_sources):\n",
    "            \n",
    "            for net_ind, (net_name, net_labels) in enumerate(network_label_dict.items()):\n",
    "\n",
    "                n_ratio = n_ratio_agg[:, fc_ind, net_ind]\n",
    "                \n",
    "                stat_res_con = stats.pearsonr(n_ratio, b_ratio)\n",
    "                stat_res_con_nl = stats.spearmanr(n_ratio, b_ratio)\n",
    "                stat_res_con_kt = stats.kendalltau(n_ratio, b_ratio)\n",
    "                \n",
    "                emp_stat_array[g_ind, fc_ind, net_ind, m_ind, 0] = stat_res_con.statistic\n",
    "                emp_stat_array[g_ind, fc_ind, net_ind, m_ind, 1] = stat_res_con.pvalue\n",
    "                \n",
    "                emp_stat_array[g_ind, fc_ind, net_ind, m_ind, 2] = stat_res_con_nl.correlation\n",
    "                emp_stat_array[g_ind, fc_ind, net_ind, m_ind, 3] = stat_res_con_nl.pvalue\n",
    "\n",
    "                emp_stat_array[g_ind, fc_ind, net_ind, m_ind, 4] = stat_res_con_kt.statistic\n",
    "                emp_stat_array[g_ind, fc_ind, net_ind, m_ind, 5] = stat_res_con_kt.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac71edfa-d32c-4fb0-bc79-d7f0710f92b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_stat_array.sel(group='Female', source='epochs', measure='sum_fc', stat=['pearson_p', 'spearman_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3f7fea-4300-43cc-9204-e098a38d1c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_linreg_emp = xr.DataArray(np.zeros((num_subject_groups, 14, num_networks, 2)), dims = ('group', 'condition_ratio', 'network', 'bound',), coords = {'group': subject_group_names, 'network': network_names, 'bound': ['l_bound', 'u_bound']})\n",
    "\n",
    "num_warmup = 200\n",
    "num_samples = 1000\n",
    "\n",
    "neu_ratio_linreg = neu_ratio_array.sel(source=1, measure='sum_fc')\n",
    "\n",
    "for g_ind, group_name in enumerate(subject_group_names):\n",
    "\n",
    "    subject_group = subject_group_dict[group_name]\n",
    "    group_length = subject_group.sum()\n",
    "\n",
    "    b_ratio = beh_ratio_array.sel(group = group_name)\n",
    "    b_ratio = b_ratio[:group_length].to_numpy()\n",
    "        \n",
    "    for net_ind, (net_name, net_labels) in enumerate(network_label_dict.items()):\n",
    "\n",
    "        n_ratio = neu_ratio_linreg.sel(group=group_name, network=net_name)[:group_length]\n",
    "    \n",
    "        x_mcmc = np.sort(n_ratio)\n",
    "        x_sorted_inds = np.argsort(n_ratio)\n",
    "        y_mcmc = b_ratio[x_sorted_inds]\n",
    "        \n",
    "        mcmc_linear = run_mcmc_from_system(linreg_system, x=x_mcmc, y=y_mcmc, num_warmup = num_warmup, num_samples = num_samples)\n",
    "        samples_linear = az.from_numpyro(mcmc_linear)\n",
    "        xdot_quantiles_linear = np.quantile(samples_linear.posterior.xdot.squeeze(),[0.05,0.95],axis=0)\n",
    "        \n",
    "        con_linreg_emp[g_ind, :group_length, net_ind, :] = xdot_quantiles_linear.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ba3ca8-931f-46ae-b551-10db2961e45e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
